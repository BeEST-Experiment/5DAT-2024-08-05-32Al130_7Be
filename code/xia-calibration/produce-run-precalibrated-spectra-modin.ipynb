{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Modin (parallel pandas) requires specific changes to typical pandas coding to allow it to work\n",
    "- More stringent need for numpy-like objects (1D)\n",
    "- Consideration of parallel gotchas (don't access objects by multiple threads e.g. use dict.copy())\n",
    "- GroupBy behaves differently (don't need `reset_index(level=0, drop=True)`)\n",
    "- Categorical columns cause some pain\n",
    "\n",
    "Written to run on a jupyter server started at the root of the repository. This enables datalad compatible coding assuming paths are from the root dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 19:07:50,131\tINFO worker.py:1786 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, glob\n",
    "from cryoant.daq.xia.listmode import load_and_process\n",
    "from beest.laser import correct_substrate_heating\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cryoant as ct\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "# import pandas as pd\n",
    "import modin.pandas as pd\n",
    "import modin.config as mcfg\n",
    "\n",
    "plt.style.use(f\"{list(ct.__path__)[0]}/plot.mpl\")\n",
    "pd.set_option(\"plotting.backend\", \"matplotlib\")\n",
    "\n",
    "DPI_VIS, DPI_SV = 200, 50\n",
    "DATE = 20240811\n",
    "\n",
    "figdir = f\"out/{DATE}/\"\n",
    "os.makedirs(figdir, exist_ok=True)\n",
    "\n",
    "df = pd.read_feather(f\"out/trace-chewing/processed/{DATE}.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = {\n",
    "    k: pd.to_datetime(\"_\".join(k.split(\"_\")[-3:-1]), format=\"%Y-%m-%d_%H.%M.%S\")\n",
    "    for k in df.fname.unique()\n",
    "}\n",
    "df[\"timestamp\"] = (\n",
    "    df.groupby(\"fname\", observed=True)\n",
    "    .fname.apply(lambda x: x.map(lambda y: timestamps.copy()[y]))\n",
    "    .reset_index(level=0, drop=True)\n",
    "    .astype(\"category\")\n",
    ")\n",
    "df[\"chunk\"] = df.fname.apply(\n",
    "    lambda x: int(x.split(\"_\")[-1].split(\".\")[0].removeprefix(\"chunk\"))\n",
    ").astype(\"category\")\n",
    "zero_timestamps = {\n",
    "    k: v for k, v in timestamps.items() if k.split(\"_\")[-1].split(\".\")[0] == \"chunk0\"\n",
    "}\n",
    "zero_timestamps = dict(sorted(zero_timestamps.items(), key=lambda x: x[1]))\n",
    "#: Create a mapping of fname to run_id. Timestamps between two zero_timestamps belong to the former run_id\n",
    "#: zero_timestamps is sorted so first, the zero files can be assigned to their run ids\n",
    "run_ids = {k: v for v, k in enumerate(zero_timestamps.keys())}\n",
    "#: Now the remainder of files need to be assinged a run id based on the latest zero file they are greater than\n",
    "for fname, timestamp in timestamps.items():\n",
    "    if fname in zero_timestamps:\n",
    "        continue\n",
    "    run_ids[fname] = [\n",
    "        run_ids[k] for k in zero_timestamps.keys() if timestamp > zero_timestamps[k]\n",
    "    ][-1]\n",
    "\n",
    "df[\"run_id\"] = df.fname.map(run_ids).astype(\"category\")\n",
    "\n",
    "#: APPLY does not work with modin (produces DataFrame). Luckily, the minimum timestamp for each run is the zero chunk timestamp.\n",
    "df[\"run_start\"] = (\n",
    "    df.groupby(\"run_id\")\n",
    "    .timestamp.transform(lambda x: pd.to_datetime(x).min())\n",
    "    .astype(\"category\")\n",
    ")\n",
    "df[\"realtime\"] = pd.to_timedelta(df.time, unit=\"s\").add(pd.to_datetime(df.run_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Do laser tagging\"\"\"\n",
    "\n",
    "df[\"ig_laser\"] = ~df.ib_head & ~df.ib_clipped & ~df.ib_flat & ~df.ib_error\n",
    "df[\"ig_event\"] = ~df.ig_laser & (\n",
    "    ~df.ib_head & ~df.ib_clipped & ~df.ib_flat & ~df.ib_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "\"\"\"Preview laser data.\n",
    "\"\"\"\n",
    "\n",
    "plt.close(\"all\")\n",
    "channels = df.channel.unique()\n",
    "for run, rungroup in df.groupby(\"run_id\"):\n",
    "    fig, axes = fig, ax = plt.subplots(\n",
    "        len(channels),\n",
    "        1,\n",
    "        figsize=(5, 3 * len(channels)),\n",
    "        dpi=DPI_VIS,\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "    fig.suptitle(f\"Run {run}\")\n",
    "\n",
    "    for (ch, chgroup), ax in zip(rungroup.groupby(\"channel\"), axes):\n",
    "        data = chgroup[\n",
    "            (chgroup.height_mV.between(*chgroup.height_mV.quantile([0, 0.99])))\n",
    "            & (chgroup.otherV.between(*chgroup.otherV.quantile([0, 0.99])))\n",
    "            & chgroup.ig_laser\n",
    "        ]\n",
    "        hb = ax.hexbin(\n",
    "            data.height_mV,\n",
    "            data.otherV,\n",
    "            gridsize=500,\n",
    "            lw=0,\n",
    "            cmap=\"inferno\",\n",
    "            norm=mpl.colors.LogNorm(),\n",
    "        )\n",
    "        cb = fig.colorbar(hb, ax=ax)\n",
    "        cb.set_label(\"log10(N)\")\n",
    "        ax.set(\n",
    "            xlabel=\"Height (mV)\",\n",
    "            ylabel=\"Other (V)\",\n",
    "            title=f\"Channel {ch}\",\n",
    "        )\n",
    "    display(fig)\n",
    "    # fig.savefig(f\"{figdir}/run{run}-laser-corrected.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "df[[\"correct\", \"gradient\"]] = (\n",
    "    df.groupby(\"channel\")\n",
    "    .apply(lambda x: pd.DataFrame(correct_substrate_heating(x.height_mV, x.sumV)).T)\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "df[\"gradient\"] = df[\"gradient\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Do substrate correction.\n",
    "\n",
    "Takes a while. May need parallelization.\n",
    "Should I use groupby or simply filter by channel/run?\n",
    "\"\"\"\n",
    "\n",
    "# TRY: Parallelize per channel and per run to correct individually\n",
    "#: Probably won't work because you can't parallel modin which already parallelizes\n",
    "#: This spun up multiple ray instances and crashed\n",
    "# with Parallel(n_jobs=-1) as parallel:\n",
    "#     results = parallel(\n",
    "#         delayed(\n",
    "#             lambda run_id, channel, group: (\n",
    "#                 run_id,\n",
    "#                 channel,\n",
    "#                 *correct_substrate_heating(group.height_mV, group.sumV),\n",
    "#             )\n",
    "#         )(run_id, channel, group)\n",
    "#         for (run_id, channel), group in df.groupby([\"run_id\", \"channel\"])\n",
    "#     )\n",
    "#     run_ids, channels, corrects, gradients = zip(*results)\n",
    "\n",
    "#     corrects_df = pd.concat(\n",
    "#         [\n",
    "#             pd.Series(\n",
    "#                 correct, index=df[(df.run_id == run_id) & (df.channel == channel)].index\n",
    "#             )\n",
    "#             for run_id, channel, correct in zip(run_ids, channels, corrects)\n",
    "#         ]\n",
    "#     )\n",
    "#     gradients_df = pd.concat(\n",
    "#         [\n",
    "#             pd.Series(\n",
    "#                 gradient,\n",
    "#                 index=df[(df.run_id == run_id) & (df.channel == channel)].index,\n",
    "#             )\n",
    "#             for run_id, channel, gradient in zip(run_ids, channels, gradients)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     df[\"correct\"] = corrects_df\n",
    "#     df[\"gradient\"] = gradients_df.astype(\"category\")\n",
    "\n",
    "# del run_ids, channels, corrects, gradients, corrects_df, gradients_df\n",
    "\n",
    "# TRY: No parallel\n",
    "#: AFAICT, this is working but slow\n",
    "# corrects = []\n",
    "# gradients = []\n",
    "\n",
    "# for run, rungroup in df.groupby(\"run_id\"):\n",
    "#     for channel, group in rungroup.groupby(\"channel\"):\n",
    "#         correct, gradient = correct_substrate_heating(\n",
    "#             group.height_mV,\n",
    "#             group.sumV,\n",
    "#             dev_plot=True,\n",
    "#             dev_dir=figdir,\n",
    "#             dev_name=f\"substrateCorrection-run{run}-ch{channel}\",\n",
    "#         )\n",
    "#         print(gradient)\n",
    "#         corrects.append(pd.Series(correct, index=group.index))\n",
    "#         gradients.append(pd.Series(gradient, index=group.index).astype(\"category\"))\n",
    "\n",
    "# df[\"correct\"] = pd.concat(corrects)\n",
    "# df[\"gradient\"] = pd.concat(gradients)\n",
    "\n",
    "# del corrects, gradients\n",
    "\n",
    "\n",
    "# TRY: Parallelize AFTER groupby\n",
    "#: If pandas operations in parallel makes modin confused, then\n",
    "#: do parallel numpy operations. Makes mapping back to DataFrame more difficult\n",
    "# NOTE: correct_substrate_heating is currently written to work with pandas objects to conserve indices\n",
    "# NOTE: Disabling modin may be as easy as df._to_pandas() which creates a non-parallelized pandas copy.\n",
    "def process_group(run_id, channel, *args, **kwargs):\n",
    "    \"\"\"Pass grouby indicators to results for concatenation.\"\"\"\n",
    "    correct, gradient = correct_substrate_heating(*args, **kwargs)\n",
    "    return (run_id, channel, correct, gradient)\n",
    "\n",
    "\n",
    "# def construct_delayed(run, ch, *modin, **kwargs):\n",
    "#     \"\"\"Change the function signature to allow for delayed.\"\"\"\n",
    "#     with mcfg.context(Engine=\"python\", BenchmarkMode=True):\n",
    "#         return delayed(process_group)(\n",
    "#             run, ch, *[m._to_pandas() for m in modin], **kwargs\n",
    "#         )\n",
    "\n",
    "grouped = df[df.ig_laser].groupby([\"run_id\", \"channel\"], observed=True)\n",
    "\n",
    "mVmins = {rid: {ch: 2.6 for ch in df.channel.unique()} for rid in df.run_id.unique()}\n",
    "#: Per run, channel mVmin assignment\n",
    "mVmins[0][14] = 3\n",
    "mVmins[0][18] = 3\n",
    "\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    #: This for loop is sequential, thus what gets parallelized is numpy only\n",
    "    # construct_delayed(\n",
    "    delayed(process_group)(\n",
    "        run,\n",
    "        ch,\n",
    "        group.height_mV._to_pandas(),\n",
    "        group.sumV._to_pandas(),\n",
    "        dev_plot=True,\n",
    "        dev_dir=figdir,\n",
    "        dev_name=f\"substrateCorrection-run{run}-ch{ch}\",\n",
    "        kwdict={\n",
    "            \"mVmin\": mVmins[run][ch],\n",
    "            \"dev_plot\": True,\n",
    "            \"dev_dir\": figdir,\n",
    "            \"dev_name\": f\"substrateCorrection-run{run}-ch{ch}\",\n",
    "        },\n",
    "    )\n",
    "    for (run, ch), group in grouped\n",
    ")\n",
    "\n",
    "runs, channels, corrects, gradients = zip(*results)\n",
    "\n",
    "# #: I don't trust that filtration or even re-grouping will maintain the index\n",
    "# #: So, use the same grouped and map the results\n",
    "# correct_map = {(run, ch): correct for run, ch, correct in zip(runs, channels, corrects)}\n",
    "# gradient_map = {\n",
    "#     (run, ch): gradient for run, ch, gradient in zip(runs, channels, gradients)\n",
    "# }\n",
    "# df[\"correct\"] = pd.concat(\n",
    "#     [\n",
    "#         pd.Series(\n",
    "#             correct_map[g[0]],\n",
    "#             index=g[1].index,\n",
    "#         )\n",
    "#         for g in grouped\n",
    "#     ]\n",
    "# )\n",
    "# df[\"gradient\"] = pd.concat(\n",
    "#     [\n",
    "#         pd.Series(\n",
    "#             gradient_map[g[0]],\n",
    "#             index=g[1].index,\n",
    "#         )\n",
    "#         for g in grouped\n",
    "#     ]\n",
    "# ).astype(\"category\")\n",
    "df.loc[\"correct\"] = pd.concat(corrects)\n",
    "df.loc[\"gradient\"] = pd.concat(gradients).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Validate the correction.\n",
    "\n",
    "Using filters takes 8m 30s\n",
    "Using groups takes 3m 13s!\n",
    "\"\"\"\n",
    "\n",
    "plt.close(\"all\")\n",
    "channels = df.channel.unique()\n",
    "for run, rungroup in df.groupby(\"run_id\"):\n",
    "    fig, axes = fig, ax = plt.subplots(\n",
    "        len(channels),\n",
    "        1,\n",
    "        figsize=(5, 3 * len(channels)),\n",
    "        dpi=DPI_VIS,\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "    fig.suptitle(f\"Run {run}\")\n",
    "\n",
    "    for (ch, chgroup), ax in zip(rungroup.groupby(\"channel\"), axes):\n",
    "        data = chgroup[\n",
    "            (chgroup.correct.between(*chgroup.correct.quantile([0, 0.99])))\n",
    "            & (chgroup.otherV.between(*chgroup.otherV.quantile([0, 0.99])))\n",
    "            & (\n",
    "                ~chgroup.ib_head\n",
    "                & ~chgroup.ib_clipped\n",
    "                & ~chgroup.ib_flat\n",
    "                & ~chgroup.ib_error\n",
    "            )\n",
    "        ]\n",
    "        hb = ax.hexbin(\n",
    "            data.correct,\n",
    "            data.otherV,\n",
    "            gridsize=500,\n",
    "            lw=0,\n",
    "            cmap=\"inferno\",\n",
    "            norm=mpl.colors.LogNorm(),\n",
    "        )\n",
    "        cb = fig.colorbar(hb, ax=ax)\n",
    "        cb.set_label(\"log10(N)\")\n",
    "        ax.set(\n",
    "            xlabel=\"Height (mV)\",\n",
    "            ylabel=\"Other (V)\",\n",
    "            title=f\"Channel {ch}\",\n",
    "        )\n",
    "    display(fig)\n",
    "    # fig.savefig(f\"{figdir}/run{run}-laser-corrected.png\")\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
