{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Validation and Spectral Extraction\n",
    "\n",
    "- Verify data processing\n",
    "- Apply timestamp and laser correction algorithms\n",
    "- Extract nuclear and laser spectra\n",
    "- Verify spectra (per channel, per dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, glob\n",
    "from cryoant.daq.xia.listmode import load_and_process\n",
    "from beest.laser import correct_substrate_heating\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cryoant as ct\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "# import pandas as pd\n",
    "import modin.pandas as pd\n",
    "import modin.config as mcfg\n",
    "\n",
    "plt.style.use(f\"{list(ct.__path__)[0]}/plot.mpl\")\n",
    "pd.set_option(\"plotting.backend\", \"matplotlib\")\n",
    "\n",
    "DPI_VIS, DPI_SV = 200, 50\n",
    "DATE = 20240808\n",
    "\n",
    "figdir = f\"out/spectra_calibration/{DATE}-setup/\"\n",
    "os.makedirs(figdir, exist_ok=True)\n",
    "\n",
    "df = pd.read_feather(f\"out/trace-chewing/processed/{DATE}.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wall-Clock Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file reuses the same eventID and times, therefore it's important to use the file time to get a real timestamp for every event before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = {\n",
    "    k: pd.to_datetime(\"_\".join(k.split(\"_\")[-3:-1]), format=\"%Y-%m-%d_%H.%M.%S\")\n",
    "    for k in df.fname.unique()\n",
    "}\n",
    "df[\"timestamp\"] = (\n",
    "    df.groupby(\"fname\", observed=True)\n",
    "    .fname.apply(lambda x: x.map(lambda y: timestamps.copy()[y]))\n",
    "    .reset_index(level=0, drop=True)\n",
    "    .astype(\"category\")\n",
    ")\n",
    "df[\"chunk\"] = df.fname.apply(\n",
    "    lambda x: int(x.split(\"_\")[-1].split(\".\")[0].removeprefix(\"chunk\"))\n",
    ").astype(\"category\")\n",
    "zero_timestamps = {\n",
    "    k: v for k, v in timestamps.items() if k.split(\"_\")[-1].split(\".\")[0] == \"chunk0\"\n",
    "}\n",
    "zero_timestamps = dict(sorted(zero_timestamps.items(), key=lambda x: x[1]))\n",
    "#: Create a mapping of fname to run_id. Timestamps between two zero_timestamps belong to the former run_id\n",
    "#: zero_timestamps is sorted so first, the zero files can be assigned to their run ids\n",
    "run_ids = {k: v for v, k in enumerate(zero_timestamps.keys())}\n",
    "#: Now the remainder of files need to be assinged a run id based on the latest zero file they are greater than\n",
    "for fname, timestamp in timestamps.items():\n",
    "    if fname in zero_timestamps:\n",
    "        continue\n",
    "    run_ids[fname] = [\n",
    "        run_ids[k] for k in zero_timestamps.keys() if timestamp > zero_timestamps[k]\n",
    "    ][-1]\n",
    "\n",
    "df[\"run_id\"] = df.fname.map(run_ids).astype(\"category\")\n",
    "\n",
    "#: APPLY does not work with modin (produces DataFrame). Luckily, the minimum timestamp for each run is the zero chunk timestamp.\n",
    "df[\"run_start\"] = (\n",
    "    df.groupby(\"run_id\")\n",
    "    .timestamp.transform(lambda x: pd.to_datetime(x).min())\n",
    "    .astype(\"category\")\n",
    ")\n",
    "df[\"realtime\"] = pd.to_timedelta(df.time, unit=\"s\").add(pd.to_datetime(df.run_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "\"\"\"Validated wall-clock time.\n",
    "\n",
    "Realtime axis is now non-repeating across all files, regardless of if multiple runs exist\n",
    "(and event ID resets)\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(10,2), dpi=250, constrained_layout=True)\n",
    "for file in df.fname.unique():\n",
    "    data = df[df.fname == file]\n",
    "    ax.plot(\n",
    "        (\n",
    "            data[\"realtime\"].astype(\"datetime64[s]\")\n",
    "            - df[\"realtime\"].astype(\"datetime64[s]\").min()\n",
    "        )/60/60,\n",
    "        data[\"eventID\"],\n",
    "    )\n",
    "ax.set(\n",
    "    xlabel=\"Time (h)\",\n",
    "    ylabel=\"Event ID\",\n",
    "    title=f\"Event ID vs Wall-Clock Time for {DATE}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laser Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification must come before substrate correction so as to not substrate correct the nuclear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Identify laser via frequency.\n",
    "\n",
    "Once identified, anticoincident is nuclear data.\n",
    "\"\"\"\n",
    "\n",
    "#: Set \"good\" data as not these bad data flags\n",
    "df[\"ig_laser\"] = ~(df.ib_head & df.ib_clipped & df.ib_flat & df.ib_error)\n",
    "\n",
    "# TRY: Do it all at once\n",
    "#   : May problematically have timing offsets between channels/runs\n",
    "# laser_hz = 100\n",
    "# df[\"ig_laser\"] = np.abs(\n",
    "#     ((df.realtime - df.realtime.min()).dt.total_seconds() % (1 / laser_hz))\n",
    "#     - ((df.realtime - df.realtime.min()).dt.total_seconds() % (1 / laser_hz))\n",
    "#     .rolling(50)\n",
    "#     .median()\n",
    "# ) < 0.05 * np.mean(\n",
    "#     (df.realtime - df.realtime.min()).dt.total_seconds() % (1 / laser_hz)\n",
    "# )\n",
    "\n",
    "# TRY: Do it by run and channel\n",
    "for run, rungroup in df.groupby(\"run_id\"):\n",
    "    for ch, chgroup in rungroup.groupby(\"channel\"):\n",
    "        df.loc[\n",
    "            (df.run_id == run) & (df.channel == ch) & (df.ig_laser), \"ig_laser\"\n",
    "        ] = np.abs(\n",
    "            (\n",
    "                (chgroup.realtime - chgroup.realtime.min()).dt.total_seconds()\n",
    "                % (1 / laser_hz)\n",
    "            )\n",
    "            - (\n",
    "                (chgroup.realtime - chgroup.realtime.min()).dt.total_seconds()\n",
    "                % (1 / laser_hz)\n",
    "            )\n",
    "            .rolling(50)\n",
    "            .median()\n",
    "        ) < 0.05 * np.mean(\n",
    "            (chgroup.realtime - chgroup.realtime.min()).dt.total_seconds()\n",
    "            % (1 / laser_hz)\n",
    "        )\n",
    "\n",
    "#: Same flags for nuclear events plus NOT laser\n",
    "df[\"ig_event\"] = ~(df.ib_head & df.ib_clipped & df.ib_flat & df.ib_error & df.ig_laser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Validate Laser Identification\"\"\"\n",
    "\n",
    "for run, rungroup in df.groupby(\"run_id\"):\n",
    "    channels = rungroup.channel.unique()\n",
    "    fig, ax = plt.subplots(\n",
    "        len(channels),\n",
    "        1,\n",
    "        figsize=(10, 4 * len(channels)),\n",
    "        dpi=200,\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "    fig.suptitle(f\"Laser Identification for {DATE}\\nRun {run}\")\n",
    "\n",
    "    for (ch, chgroup), ax in zip(rungroup.groupby(\"channel\"), ax):\n",
    "        ax.scatter(\n",
    "            (chgroup.realtime - chgroup.realtime.min()).dt.total_seconds(),\n",
    "            (chgroup.realtime - chgroup.realtime.min()).dt.total_seconds()\n",
    "            % (1 / laser_hz),\n",
    "            s=0.1,\n",
    "            lw=0,\n",
    "            alpha=0.5,\n",
    "            label=\"All\",\n",
    "        )\n",
    "        data = chgroup[chgroup.ig_laser]\n",
    "        ax.scatter(\n",
    "            (data.realtime - data.realtime.min()).dt.total_seconds(),\n",
    "            (data.realtime - data.realtime.min()).dt.total_seconds() % (1 / laser_hz),\n",
    "            s=0.1,\n",
    "            lw=0,\n",
    "            alpha=0.5,\n",
    "            label=\"Laser ID (rolling 50x median)\",\n",
    "        )\n",
    "        ax.set(\n",
    "            xlabel=\"Time since start (s)\",\n",
    "            ylabel=f\"Time modulo 1/{laser_hz} s\",\n",
    "            title=f\"Channel {ch}\",\n",
    "        )\n",
    "        ax.legend(loc=\"lower left\", bbox_to_anchor=(1, 1))\n",
    "    display(fig)\n",
    "    fig.savefig(\n",
    "        os.path.join(figdir, f\"laserIdentification_{laser_hz}Hz-run{run}-ch{ch}.png\")\n",
    "    )\n",
    "    print(\n",
    "        f\"Saved {os.path.join(figdir, f'laserIdentification_{laser_hz}Hz-run{run}-ch{ch}.png')}\"\n",
    "    )\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laser Substrate Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Do substrate correction.\n",
    "\n",
    "Takes a while. May need parallelization.\n",
    "Should I use groupby or simply filter by channel/run?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#: Parallelize AFTER groupby\n",
    "#: If pandas operations in parallel makes modin confused, then\n",
    "#: do parallel numpy operations. Makes mapping back to DataFrame more difficult\n",
    "def process_group(run_id, channel, *args, **kwargs):\n",
    "    \"\"\"Pass grouby indicators to results for concatenation.\"\"\"\n",
    "    correct, gradient = correct_substrate_heating(*args, **kwargs)\n",
    "    return (run_id, channel, correct, gradient)\n",
    "\n",
    "\n",
    "grouped = df[df.ig_laser].groupby([\"run_id\", \"channel\"], observed=True)\n",
    "\n",
    "mVmins = {rid: {ch: 2.6 for ch in df.channel.unique()} for rid in df.run_id.unique()}\n",
    "#: Per run, channel mVmin assignment\n",
    "mVmins[0][14] = 3\n",
    "mVmins[0][18] = 3\n",
    "\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    #: This for loop is sequential, thus what gets parallelized is numpy only\n",
    "    # construct_delayed(\n",
    "    delayed(process_group)(\n",
    "        run,\n",
    "        ch,\n",
    "        group.height_mV._to_pandas(),\n",
    "        group.sumV._to_pandas(),\n",
    "        dev_plot=True,\n",
    "        dev_dir=figdir,\n",
    "        dev_name=f\"substrateCorrection-run{run}-ch{ch}\",\n",
    "        kwdict={\n",
    "            \"mVmin\": mVmins[run][ch],\n",
    "            \"dev_plot\": True,\n",
    "            \"dev_dir\": figdir,\n",
    "            \"dev_name\": f\"substrateCorrection-run{run}-ch{ch}\",\n",
    "        },\n",
    "    )\n",
    "    for (run, ch), group in grouped\n",
    ")\n",
    "\n",
    "runs, channels, corrects, gradients = zip(*results)\n",
    "\n",
    "df.loc[\"correct\"] = pd.concat(corrects)\n",
    "df.loc[\"gradient\"] = pd.concat(gradients).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Validate the correction.\n",
    "\n",
    "Takes ~3m\n",
    "\"\"\"\n",
    "\n",
    "plt.close(\"all\")\n",
    "data = df[df.ig_laser]\n",
    "channels = data.channel.unique()\n",
    "for run, rungroup in data.groupby(\"run_id\"):\n",
    "    fig, axes = fig, ax = plt.subplots(\n",
    "        len(channels),\n",
    "        1,\n",
    "        figsize=(5, 3 * len(channels)),\n",
    "        dpi=DPI_VIS,\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "    fig.suptitle(f\"Run {run}\")\n",
    "\n",
    "    for (ch, chgroup), ax in zip(rungroup.groupby(\"channel\"), axes):\n",
    "        data = chgroup[\n",
    "            (chgroup.correct.between(*chgroup.correct.quantile([0, 0.99])))\n",
    "            & (chgroup.otherV.between(*chgroup.otherV.quantile([0, 0.99])))\n",
    "        ]\n",
    "        hb = ax.hexbin(\n",
    "            data.correct,\n",
    "            data.otherV,\n",
    "            gridsize=500,\n",
    "            lw=0,\n",
    "            cmap=\"inferno\",\n",
    "            norm=mpl.colors.LogNorm(),\n",
    "        )\n",
    "        cb = fig.colorbar(hb, ax=ax)\n",
    "        cb.set_label(\"log10(N)\")\n",
    "        ax.set(\n",
    "            xlabel=\"Height (mV)\",\n",
    "            ylabel=\"Other (V)\",\n",
    "            title=f\"Channel {ch}\",\n",
    "        )\n",
    "    display(fig)\n",
    "    fig.savefig(os.path.join(figdir, f\"run{run}-laser-corrected.png\"))\n",
    "    print(f\"Saved {os.path.join(figdir, f'run{run}-laser-corrected.png')}\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "\"\"\"Validate laser correction.\n",
    "\n",
    "Unlikely useful here as laser wasn't very well resolved across all runs.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=200, constrained_layout=True)\n",
    "for file in df.fname.unique():\n",
    "    d = df[(df.fname == file) & (df.ig_laser)]\n",
    "    ax.scatter(d.height_mV, d.otherV, s=0.1, lw=0, alpha=0.1, label=file)\n",
    "ax.legend(\n",
    "    loc=\"upper right\",\n",
    "    fontsize=8,\n",
    "    # title=\"File\",\n",
    "    # title_fontsize=8,\n",
    "    # shadow=True,\n",
    "    # fancybox=True,\n",
    "    # frameon=True,\n",
    "    # framealpha=0.5,\n",
    "    # edgecolor=\"black\",\n",
    "    # facecolor=\"white\",\n",
    "    ncol=2,\n",
    "    markerscale=10,\n",
    "    scatterpoints=10,\n",
    "    # handletextpad=0.1,\n",
    "    # handlelength=0.5,\n",
    "    # handleheight=0.5,\n",
    "    # borderpad=0.1,\n",
    "    # labelspacing=0.1,\n",
    "    # columnspacing=0.1,\n",
    "    # numpoints=1,\n",
    "    # mode=\"expand\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    # bbox_transform=None,\n",
    "    # handler_map=None,\n",
    ")\n",
    "fig.savefig(os.path.join(figdir,\"laserCorrected-hexbin.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(f\"out/spectra_calibration/{DATE}-setup.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuclear Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Laser Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Per Channel Nuclear Data\n",
    "\n",
    "~ig_laser\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "channels = df.channel.unique()\n",
    "fig, axes = plt.subplots(\n",
    "    len(channels),\n",
    "    1,\n",
    "    figsize=(8, 3.2 * len(channels)),\n",
    "    dpi=DPI_VIS,\n",
    "    constrained_layout=True,\n",
    ")\n",
    "for channel, ax in list(zip(channels, np.ravel(axes))):\n",
    "    range = (0, 50)\n",
    "    bins = 1000\n",
    "    if channel == 27:\n",
    "        bins = 350\n",
    "        range = (0, 25)\n",
    "    data = df[(df.channel == channel) & (~df.ig_laser)]\n",
    "    h, b = np.histogram(data.height_mV, bins=bins, range=range)\n",
    "    ax.step(b[:-1], h, where=\"post\", label=\"All Laser-Anticoincident Data\", zorder=-21)\n",
    "    for mxmult in [2, 4, 6, 8, 10, 15, 20]:\n",
    "        data = df[(df.channel == channel) & (~df.ig_laser) & (df.multiplicity < mxmult)]\n",
    "        h, b = np.histogram(data.height_mV, bins=bins, range=range)\n",
    "        ax.step(\n",
    "            b[:-1], h, where=\"post\", label=f\"Multiplicity < {mxmult}\", zorder=-mxmult\n",
    "        )\n",
    "    ax.set(\n",
    "        title=f\"Channel {channel}\",\n",
    "        xlabel=\"Height [mV]\",\n",
    "        ylabel=\"Counts\",\n",
    "        yscale=\"log\",\n",
    "    )\n",
    "    ax.legend()\n",
    "display(fig)\n",
    "fig.savefig(os.path.join(figdir, \"per_channel-nuclear_data-laser_anticoincidence.png\"))\n",
    "print(\n",
    "    f\"Saved {os.path.join(figdir, 'per_channel-nuclear_data-laser_anticoincidence.png')}\"\n",
    ")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
