{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Validation and Spectral Extraction\n",
    "\n",
    "- Verify data processing\n",
    "- Apply timestamp and laser correction algorithms\n",
    "- Extract nuclear and laser spectra\n",
    "- Verify spectra (per channel, per dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, glob\n",
    "from cryoant.daq.xia.listmode import load_and_process\n",
    "from beest.laser import correct_substrate_heating\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import cryoant as ct\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "# import pandas as pd\n",
    "import modin.pandas as pd\n",
    "import modin.config as mcfg\n",
    "\n",
    "plt.style.use(f\"{list(ct.__path__)[0]}/plot.mpl\")\n",
    "pd.set_option(\"plotting.backend\", \"matplotlib\")\n",
    "\n",
    "DPI_VIS, DPI_SV = 200, 50\n",
    "DATE = 20240725\n",
    "\n",
    "figdir = f\"out/spectra_calibration/{DATE}-setup/\"\n",
    "os.makedirs(figdir, exist_ok=True)\n",
    "\n",
    "df = pd.read_feather(f\"out/trace-chewing/processed/{DATE}.feather\")\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wall-Clock Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file reuses the same eventID and times, therefore it's important to use the file time to get a real timestamp for every event before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = {\n",
    "    k: pd.to_datetime(\"_\".join(k.split(\"_\")[-3:-1]), format=\"%Y-%m-%d_%H.%M.%S\")\n",
    "    for k in df.fname.unique()\n",
    "}\n",
    "df[\"timestamp\"] = (\n",
    "    df.groupby(\"fname\", observed=True)\n",
    "    .fname.apply(lambda x: x.map(lambda y: timestamps.copy()[y]))\n",
    "    .reset_index(level=0, drop=True)\n",
    "    .astype(\"category\")\n",
    ")\n",
    "df[\"chunk\"] = df.fname.apply(\n",
    "    lambda x: int(x.split(\"_\")[-1].split(\".\")[0].removeprefix(\"chunk\"))\n",
    ").astype(\"category\")\n",
    "zero_timestamps = {\n",
    "    k: v for k, v in timestamps.items() if k.split(\"_\")[-1].split(\".\")[0] == \"chunk0\"\n",
    "}\n",
    "zero_timestamps = dict(sorted(zero_timestamps.items(), key=lambda x: x[1]))\n",
    "#: Create a mapping of fname to run_id. Timestamps between two zero_timestamps belong to the former run_id\n",
    "#: zero_timestamps is sorted so first, the zero files can be assigned to their run ids\n",
    "run_ids = {k: v for v, k in enumerate(zero_timestamps.keys())}\n",
    "#: Now the remainder of files need to be assinged a run id based on the latest zero file they are greater than\n",
    "for fname, timestamp in timestamps.items():\n",
    "    if fname in zero_timestamps:\n",
    "        continue\n",
    "    run_ids[fname] = [\n",
    "        run_ids[k] for k in zero_timestamps.keys() if timestamp > zero_timestamps[k]\n",
    "    ][-1]\n",
    "\n",
    "df[\"run_id\"] = df.fname.map(run_ids).astype(\"category\")\n",
    "\n",
    "#: APPLY does not work with modin (produces DataFrame). Luckily, the minimum timestamp for each run is the zero chunk timestamp.\n",
    "for _, g in df.groupby(\"run_id\"):\n",
    "    df.loc[g.index, \"run_start\"] = g[\"timestamp\"].astype(\"datetime64[ns]\").min()\n",
    "df[\"realtime\"] = pd.Series(pd.to_timedelta(df.time, unit=\"s\")).add(\n",
    "    pd.to_datetime(df.run_start.astype(str))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "\"\"\"Validated wall-clock time.\n",
    "\n",
    "Realtime axis is now non-repeating across all files, regardless of if multiple runs exist\n",
    "(and event ID resets)\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(10,2), dpi=250, constrained_layout=True)\n",
    "for file in df.fname.unique():\n",
    "    data = df[df.fname == file]\n",
    "    ax.plot(\n",
    "        (\n",
    "            data[\"realtime\"].astype(\"datetime64[s]\")\n",
    "            - df[\"realtime\"].astype(\"datetime64[s]\").min()\n",
    "        )/60/60,\n",
    "        data[\"eventID\"],\n",
    "    )\n",
    "ax.set(\n",
    "    xlabel=\"Time (h)\",\n",
    "    ylabel=\"Event ID\",\n",
    "    title=f\"Event ID vs Wall-Clock Time for {DATE}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laser Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification must come before substrate correction so as to not substrate correct the nuclear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup: Good Event Selection\"\"\"\n",
    "\n",
    "#: Generally good data\n",
    "df[\"ig_data\"] = ~(df.ib_head | df.ib_clipped | df.ib_flat | df.ib_error)\n",
    "\n",
    "#: Initial Setting of laser/nuclear data\n",
    "df[\"ig_laser\"] = False\n",
    "df[\"ig_event\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup: Laser Frequencies per Run\"\"\"\n",
    "\n",
    "laser_hzs = {k: 100 for k in df.run_id.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Identify laser via frequency.\n",
    "\n",
    "Once identified, anticoincident is nuclear data.\n",
    "\"\"\"\n",
    "\n",
    "groups = []\n",
    "for (run, ch), chgroup in df[df.ig_data].groupby([\"run_id\", \"channel\"]):\n",
    "    groups.append(\n",
    "        (\n",
    "            (\n",
    "                (chgroup.realtime - chgroup.realtime.min()).dt.total_seconds()\n",
    "                % (1 / laser_hzs[run])\n",
    "            )\n",
    "            - (\n",
    "                (chgroup.realtime - chgroup.realtime.min()).dt.total_seconds()\n",
    "                % (1 / laser_hzs[run])\n",
    "            )\n",
    "            .rolling(50)\n",
    "            .median()\n",
    "        )\n",
    "        .abs()\n",
    "        .lt(\n",
    "            0.05\n",
    "            * (\n",
    "                (chgroup.realtime - chgroup.realtime.min()).dt.total_seconds()\n",
    "                % (1 / laser_hzs[run])\n",
    "            ).mean()\n",
    "        )\n",
    "    )\n",
    "\n",
    "df[\"ig_laser\"] = pd.concat(groups).reindex(df.index).fillna(df.ig_laser)\n",
    "\n",
    "del groups\n",
    "\n",
    "#: Same flags for nuclear events plus NOT laser\n",
    "df[\"ig_event\"] = ~(df.ib_head | df.ib_clipped | df.ib_flat | df.ib_error | df.ig_laser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Validate Laser Identification\n",
    "\n",
    "Modulo\n",
    "\"\"\"\n",
    "\n",
    "runs = df.run_id.unique()\n",
    "channels = df.channel.unique()\n",
    "fig, axes = plt.subplots(\n",
    "    len(runs),\n",
    "    len(channels),\n",
    "    figsize=(10 * len(channels), 4 * len(runs)),\n",
    "    dpi=200,\n",
    "    constrained_layout=True,\n",
    ")\n",
    "if len(runs) == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)\n",
    "if len(channels) == 1:\n",
    "    axes = np.expand_dims(axes, axis=1)\n",
    "fig.suptitle(f\"Laser Identification for {DATE}\")\n",
    "\n",
    "for (run, channel), chgroup in df[df.ig_data].groupby([\"run_id\", \"channel\"]):\n",
    "    i = np.where(runs == run)[0][0]\n",
    "    j = np.where(channels == channel)[0][0]\n",
    "    ax = axes[i, j]\n",
    "    ax.scatter(\n",
    "        (chgroup.realtime - df.realtime.min()).dt.total_seconds(),\n",
    "        (chgroup.realtime - df.realtime.min()).dt.total_seconds()\n",
    "        % (1 / laser_hzs[run]),\n",
    "        s=0.1,\n",
    "        lw=0,\n",
    "        alpha=0.5,\n",
    "        label=\"All\",\n",
    "    )\n",
    "    data = chgroup[chgroup.ig_laser]\n",
    "    ax.scatter(\n",
    "        (data.realtime - df.realtime.min()).dt.total_seconds(),\n",
    "        (data.realtime - df.realtime.min()).dt.total_seconds() % (1 / laser_hzs[run]),\n",
    "        s=0.1,\n",
    "        lw=0,\n",
    "        alpha=0.5,\n",
    "        label=\"Laser ID (rolling 50x median)\",\n",
    "    )\n",
    "    ax.set(\n",
    "        xlabel=\"Time since start (s)\",\n",
    "        ylabel=f\"Time modulo 1/{laser_hzs[run]} s\",\n",
    "        title=f\"Run {run}, Channel {channel}\",\n",
    "    )\n",
    "    ax.legend(loc=\"lower left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "del ax, data, run, channel, chgroup, i, j\n",
    "\n",
    "display(fig)\n",
    "fig.savefig(os.path.join(figdir, f\"laserIdentification.png\"))\n",
    "print(f\"Saved {os.path.join(figdir, f'laserIdentification.png')}\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Validate Laser Identification\n",
    "\n",
    "Spectra\n",
    "\"\"\"\n",
    "\n",
    "plt.close(\"all\")\n",
    "runs = df.run_id.unique()\n",
    "channels = df.channel.unique()\n",
    "fig, axes = plt.subplots(\n",
    "    len(runs),\n",
    "    len(channels),\n",
    "    figsize=(5 * len(channels), 3 * len(runs)),\n",
    "    dpi=200,\n",
    "    constrained_layout=True,\n",
    ")\n",
    "axes = np.array(fig.axes).reshape(len(runs), len(channels))\n",
    "fig.suptitle(f\"Corrected Laser for {DATE}\")\n",
    "\n",
    "for group in df[df.ig_data].groupby([\"run_id\", \"channel\"]):\n",
    "    assert isinstance(group[0], tuple)\n",
    "    run, channel = tuple(group[0])\n",
    "    chgroup = group[1]\n",
    "    i = np.where(runs == run)[0][0]\n",
    "    j = np.where(channels == channel)[0][0]\n",
    "    ax = axes[i, j]\n",
    "    assert isinstance(ax, type(fig.axes[0])), f\"Expected AxesSubplot, got {type(ax)}\"\n",
    "    data = chgroup[\n",
    "        (chgroup.height_mV.between(*chgroup.height_mV.quantile([0, 0.99])))\n",
    "        & (chgroup.otherV.between(*chgroup.otherV.quantile([0, 0.99])))\n",
    "    ]\n",
    "    hb = ax.hexbin(\n",
    "        data.height_mV,\n",
    "        data.otherV,\n",
    "        gridsize=500,\n",
    "        lw=0,\n",
    "        cmap=\"inferno\",\n",
    "        norm=colors.LogNorm(),\n",
    "    )\n",
    "    cb = fig.colorbar(hb, ax=ax)\n",
    "    cb.set_label(\"log10(N)\")\n",
    "    ax.set(\n",
    "        xlabel=\"Height (mV)\",\n",
    "        ylabel=\"Other (V)\",\n",
    "        title=f\"Channel {channel}\",\n",
    "    )\n",
    "\n",
    "display(fig)\n",
    "fig.savefig(os.path.join(figdir, f\"laser-precorrected.png\"))\n",
    "print(f\"Saved {os.path.join(figdir, f'laser-precorrected.png')}\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laser Substrate Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup: Specific min frequency selections\n",
    "\n",
    "Varies per channel and dataset based on STJ gain and noise\n",
    "\"\"\"\n",
    "\n",
    "mVmins = {rid: {ch: 2.6 for ch in df.channel.unique()} for rid in df.run_id.unique()}\n",
    "#: Per run, channel mVmin assignment\n",
    "# mVmins[0][18] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Do substrate correction.\n",
    "\n",
    "Takes a while. May need parallelization.\n",
    "Should I use groupby or simply filter by channel/run?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#: Parallelize AFTER groupby\n",
    "#: If pandas operations in parallel makes modin confused, then\n",
    "#: do parallel numpy operations. Makes mapping back to DataFrame more difficult\n",
    "def process_group(run_id, channel, *args, **kwargs):\n",
    "    \"\"\"Pass grouby indicators to results for concatenation.\"\"\"\n",
    "    correct, gradient = correct_substrate_heating(*args, **kwargs)\n",
    "    return (run_id, channel, correct, gradient)\n",
    "\n",
    "\n",
    "grouped = df[df.ig_laser].groupby([\"run_id\", \"channel\"], observed=True)\n",
    "\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    #: This for loop is sequential, thus what gets parallelized is numpy only\n",
    "    # construct_delayed(\n",
    "    delayed(process_group)(\n",
    "        run,\n",
    "        ch,\n",
    "        group.height_mV._to_pandas(),\n",
    "        group.sumV._to_pandas(),\n",
    "        dev_plot=True,\n",
    "        dev_dir=figdir,\n",
    "        dev_name=f\"substrateCorrection-run{run}-ch{ch}\",\n",
    "        kwdict={\n",
    "            \"mVmin\": mVmins[run][ch],\n",
    "            \"dev_plot\": True,\n",
    "            \"dev_dir\": figdir,\n",
    "            \"dev_name\": f\"substrateCorrection-run{run}-ch{ch}\",\n",
    "        },\n",
    "    )\n",
    "    for (run, ch), group in grouped\n",
    ")\n",
    "\n",
    "runs, channels, corrects, gradients = zip(*results)\n",
    "\n",
    "df.loc[\"correct\"] = pd.concat(corrects).reindex(df.index)\n",
    "df.loc[\"gradient\"] = pd.concat(gradients).reindex(df.index).astype(\"category\")\n",
    "\n",
    "del grouped, results, runs, channels, corrects, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Validate the correction.\n",
    "\n",
    "Takes ~3m\n",
    "\"\"\"\n",
    "\n",
    "plt.close(\"all\")\n",
    "runs = df.run_id.unique()\n",
    "channels = df.channel.unique()\n",
    "fig, axes = plt.subplots(\n",
    "    len(runs),\n",
    "    len(channels),\n",
    "    figsize=(5 * len(channels), 3 * len(runs)),\n",
    "    dpi=200,\n",
    "    constrained_layout=True,\n",
    ")\n",
    "axes = np.array(fig.axes).reshape(len(runs), len(channels))\n",
    "fig.suptitle(f\"Corrected Laser for {DATE}\")\n",
    "\n",
    "for group in df[df.ig_data].groupby([\"run_id\", \"channel\"]):\n",
    "    assert isinstance(group[0], tuple)\n",
    "    run, channel = tuple(group[0])\n",
    "    chgroup = group[1]\n",
    "    i = np.where(runs == run)[0][0]\n",
    "    j = np.where(channels == channel)[0][0]\n",
    "    ax = axes[i, j]\n",
    "    assert isinstance(ax, type(fig.axes[0])), f\"Expected AxesSubplot, got {type(ax)}\"\n",
    "    data = chgroup[\n",
    "        (chgroup.correct.between(*chgroup.correct.quantile([0, 0.99])))\n",
    "        & (chgroup.otherV.between(*chgroup.otherV.quantile([0, 0.99])))\n",
    "    ]\n",
    "    hb = ax.hexbin(\n",
    "        data.correct,\n",
    "        data.otherV,\n",
    "        gridsize=500,\n",
    "        lw=0,\n",
    "        cmap=\"inferno\",\n",
    "        norm=colors.LogNorm(),\n",
    "    )\n",
    "    cb = fig.colorbar(hb, ax=ax)\n",
    "    cb.set_label(\"log10(N)\")\n",
    "    ax.set(\n",
    "        xlabel=\"Height (mV)\",\n",
    "        ylabel=\"Other (V)\",\n",
    "        title=f\"Channel {channel}\",\n",
    "    )\n",
    "\n",
    "display(fig)\n",
    "fig.savefig(os.path.join(figdir, f\"run{run}-laser-corrected.png\"))\n",
    "print(f\"Saved {os.path.join(figdir, f'run{run}-laser-corrected.png')}\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "\"\"\"Validate laser correction.\n",
    "\n",
    "Unlikely useful here as laser wasn't very well resolved across all runs.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=200, constrained_layout=True)\n",
    "for file in df.fname.unique():\n",
    "    d = df[(df.fname == file) & (df.ig_laser)]\n",
    "    ax.scatter(d.height_mV, d.otherV, s=0.1, lw=0, alpha=0.1, label=file)\n",
    "ax.legend(\n",
    "    loc=\"upper right\",\n",
    "    fontsize=8,\n",
    "    # title=\"File\",\n",
    "    # title_fontsize=8,\n",
    "    # shadow=True,\n",
    "    # fancybox=True,\n",
    "    # frameon=True,\n",
    "    # framealpha=0.5,\n",
    "    # edgecolor=\"black\",\n",
    "    # facecolor=\"white\",\n",
    "    ncol=2,\n",
    "    markerscale=10,\n",
    "    scatterpoints=10,\n",
    "    # handletextpad=0.1,\n",
    "    # handlelength=0.5,\n",
    "    # handleheight=0.5,\n",
    "    # borderpad=0.1,\n",
    "    # labelspacing=0.1,\n",
    "    # columnspacing=0.1,\n",
    "    # numpoints=1,\n",
    "    # mode=\"expand\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    # bbox_transform=None,\n",
    "    # handler_map=None,\n",
    ")\n",
    "fig.savefig(os.path.join(figdir,\"laserCorrected-hexbin.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(f\"out/spectra_calibration/{DATE}-setup.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuclear Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Laser Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Per Channel Nuclear Data\n",
    "\n",
    "~ig_laser\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "channels = df.channel.unique()\n",
    "fig, axes = plt.subplots(\n",
    "    len(channels),\n",
    "    1,\n",
    "    figsize=(8, 3.2 * len(channels)),\n",
    "    dpi=DPI_VIS,\n",
    "    constrained_layout=True,\n",
    ")\n",
    "for channel, ax in list(zip(channels, np.ravel(axes))):\n",
    "    range = (0, 50)\n",
    "    bins = 1000\n",
    "    if channel == 27:\n",
    "        bins = 350\n",
    "        range = (0, 25)\n",
    "    data = df[(df.channel == channel) & (~df.ig_laser)]\n",
    "    h, b = np.histogram(data.height_mV, bins=bins, range=range)\n",
    "    ax.step(b[:-1], h, where=\"post\", label=\"All Laser-Anticoincident Data\", zorder=-21)\n",
    "    for mxmult in [2, 4, 6, 8, 10, 15, 20]:\n",
    "        data = df[(df.channel == channel) & (~df.ig_laser) & (df.multiplicity < mxmult)]\n",
    "        h, b = np.histogram(data.height_mV, bins=bins, range=range)\n",
    "        ax.step(\n",
    "            b[:-1], h, where=\"post\", label=f\"Multiplicity < {mxmult}\", zorder=-mxmult\n",
    "        )\n",
    "    ax.set(\n",
    "        title=f\"Channel {channel}\",\n",
    "        xlabel=\"Height [mV]\",\n",
    "        ylabel=\"Counts\",\n",
    "        yscale=\"log\",\n",
    "    )\n",
    "    ax.legend()\n",
    "display(fig)\n",
    "fig.savefig(os.path.join(figdir, \"per_channel-nuclear_data-laser_anticoincidence.png\"))\n",
    "print(\n",
    "    f\"Saved {os.path.join(figdir, 'per_channel-nuclear_data-laser_anticoincidence.png')}\"\n",
    ")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
