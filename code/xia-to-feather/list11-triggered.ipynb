{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61114904",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad881ff-c00c-4380-b556-52b23f8496f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from cryoant.daq.xia.listmode import load_and_process\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cryoant as ct\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import express as px\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "plt.style.use(f\"{list(ct.__path__)[0]}/plot.mpl\")\n",
    "\n",
    "DPI_VIS, DPI_SV = 200, 50\n",
    "DATE = \"240812\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ig_laser\"] = np.abs(\n",
    "    (df.time % 1 / 300) - (df.time % 1 / 300).rolling(1000).median()\n",
    ") < 0.05 * np.mean(df.time % 1 / 300)\n",
    "df[\"ig_laser\"] = df.ig_laser & df.ig_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9995ff6-bad5-414c-a25d-57ecac8bc455",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "directory = \"/beest_data/summer2024/Be7_Ta_PR_Mask_listmode_ben/d/\"\n",
    "files = glob.glob(os.path.join(directory, \"*_Al_*/*.bin\"))\n",
    "# files = glob.glob(os.path.join(directory, \"*.bin\"))\n",
    "\n",
    "# Sort files by filesize\n",
    "files.sort(key=os.path.getsize)\n",
    "# files.sort(key=lambda x: x.split(\"/\")[-1])\n",
    "files = [file for file in files if os.path.getsize(file) > 2e9]\n",
    "files = [file for file in files if DATE in file]\n",
    "\n",
    "dev_file = files[\n",
    "    0\n",
    "]  # for this file, which is currently 7-22 chunk34, the best channel for spectrum seems to be 28, and tpz is 250.5\n",
    "dev_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"out/processed/240812.h5\", key=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ac91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m cryoant.daq.xia.listmode dataset-processor \"240812\" -k kwfile.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341c273-9471-4587-93ab-6ac4d0b4a991",
   "metadata": {},
   "source": [
    "## Spectrum from single 2 GB listmode output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a181ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "OMP_NUM_THREADS = os.environ[\"OMP_NUM_THREADS\"] # export OMP_NUM_THREADS=1\n",
    "OPENBLAS_NUM_THREADS = os.environ[\"OPENBLAS_NUM_THREADS\"] # export OPENBLAS_NUM_THREADS=1\n",
    "MKL_NUM_THREADS = os.environ[\"MKL_NUM_THREADS\"] # export MKL_NUM_THREADS=1\n",
    "VECLIB_MAXIMUM_THREADS = os.environ[\"VECLIB_MAXIMUM_THREADS\"] # export VECLIB_MAXIMUM_THREADS=1\n",
    "NUMEXPR_NUM_THREADS = os.environ[\"NUMEXPR_NUM_THREADS\"] # export NUMEXPR_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa84ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "\"\"\"Set to Existing Values\"\"\"    \n",
    "os.environ[\"OMP_NUM_THREADS\"] = OMP_NUM_THREADS # export OMP_NUM_THREADS=1\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = OPENBLAS_NUM_THREADS # export OPENBLAS_NUM_THREADS=1\n",
    "os.environ[\"MKL_NUM_THREADS\"] = MKL_NUM_THREADS # export MKL_NUM_THREADS=1\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = VECLIB_MAXIMUM_THREADS # export VECLIB_MAXIMUM_THREADS=1\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = NUMEXPR_NUM_THREADS # export NUMEXPR_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb667d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: Load and Process a File\n",
    "kwdict = dict(\n",
    "    rise=450,\n",
    "    flat=50,\n",
    "    fast=50,\n",
    "    start_tpz=400,\n",
    "    max_tpz=8000,\n",
    "    debug_plots=False,\n",
    "    outdir=\"out\",\n",
    ")\n",
    "\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # export OMP_NUM_THREADS=1\n",
    "# os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"  # export OPENBLAS_NUM_THREADS=1\n",
    "# os.environ[\"MKL_NUM_THREADS\"] = \"1\"  # export MKL_NUM_THREADS=1\n",
    "# os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"  # export VECLIB_MAXIMUM_THREADS=1\n",
    "# os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"  # export NUMEXPR_NUM_THREADS=1\n",
    "\n",
    "dfs = []\n",
    "df, header, opt_tpzs = load_and_process(\n",
    "    files[-1], multithread=True, drop_trace=True, events_total=1e6, kwdict=kwdict\n",
    ")\n",
    "dfs.append(df)\n",
    "for file in files[-5:-1]:\n",
    "    df, _, _ = load_and_process(\n",
    "        file,\n",
    "        multithread=True,\n",
    "        drop_trace=True,\n",
    "        events_total=1e6,\n",
    "        kwdict=kwdict,\n",
    "        known_tpz=opt_tpzs,\n",
    "    )\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df.to_hdf(\"out/processed/240812.h5\", key=\"df\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780dc13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[-3].split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9a35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "_VSCode_matplotLib_FigureFormats = (\n",
    "    matplotlib_inline.backend_inline.InlineBackend.instance().figure_formats\n",
    ")\n",
    "_VSCode_matplotLib_FigureFormats.add(\"svg\")\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\n",
    "    *_VSCode_matplotLib_FigureFormats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b910ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "h, b = np.histogram(df.pulse_onset, bins=500)\n",
    "fig = go.Figure(data=[go.Scatter(x=b[:-1], y=h, mode='lines', line=dict(shape='hv'))])\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=300,\n",
    "    title=\"Pulse Onset Histogram\",\n",
    "    xaxis_title=\"Bins\",\n",
    "    yaxis_title=\"Counts\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c93f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, b = np.histogram(df.pulse_onset, bins=500)\n",
    "plt.figure(figsize=(8, 3), dpi=DPI_SV)\n",
    "plt.step(b[:-1], h, where=\"mid\")\n",
    "# plt.gca().set(xlim=(0, len(df.trace[0])))\n",
    "display(plt.gcf())\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93f18c",
   "metadata": {},
   "source": [
    "## Ideal Filter Parameters\n",
    "\n",
    "PZ is probably fine, but we need to try different shaping times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a495e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in df.channel.unique():\n",
    "    h, b = np.histogram(\n",
    "        df[(df.channel == channel)].height_mV,\n",
    "        bins=2000,\n",
    "        range=(0, 50),\n",
    "    )\n",
    "    fig, ax = plt.subplots(dpi=DPI_VIS)\n",
    "    ax.step(b[:-1], h)\n",
    "    ax.set(\n",
    "        xlabel=\"Height\",\n",
    "        ylabel=\"Counts\",\n",
    "        title=f\"Spectrum Channel {channel}\",\n",
    "        yscale=\"log\",\n",
    "        xlim=(0, 50),\n",
    "    )\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0dccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "\"\"\"Shaping Validation\n",
    "\"\"\"\n",
    "from cryoant.daq.xia.listmode import shaping_tester, kwfilt\n",
    "\n",
    "kwdict = dict(rise=400, flat=150, fast=50, start_tpz=300, end_tpz=1200, step=5)\n",
    "\n",
    "for channel in df.channel.unique():\n",
    "    col, heights, fast_amps, onsets = shaping_tester(\n",
    "        df[(df.channel == channel) & (df.multiplicity > 5)],\n",
    "        opt_tpzs,\n",
    "        kwdict,\n",
    "        **kwfilt(kwdict, shaping_tester)\n",
    "    )\n",
    "\n",
    "    h, b = np.histogram(heights, bins=500)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.step(b[:-1], h)\n",
    "    ax.set(\n",
    "        xlabel=\"Height\",\n",
    "        ylabel=\"Counts\",\n",
    "        title=\"Height Spectrum\",\n",
    "        yscale=\"log\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture out\n",
    "%%\n",
    "from cryoant.daq.xia.listmode import get_pulse_height\n",
    "\n",
    "for i in np.random.randint(0, len(df), 5):\n",
    "    get_pulse_height(\n",
    "        df.iloc[i].trace,\n",
    "        **kwfilt(kwdict, get_pulse_height, tpz=opt_tpzs[df.iloc[i].channel]),\n",
    "        debug_plot=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf8001",
   "metadata": {},
   "source": [
    "OK so TPZ are really bad, let's debug that first:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c39473e",
   "metadata": {},
   "source": [
    "#TODO The fact that purple and the green trapezoid with the red flat are not the same exact trapezoid is a real problem because these are simply the filtered result as done in the_filter and done manually using trapezoidalFilter. They should be the same. Why are they not????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "from cryoant.daq.xia.listmode import get_best_tpz\n",
    "\n",
    "kwdict = kwdict | dict(start_tpz=500, end_tpz=4000, step=50)\n",
    "display(kwdict)\n",
    "for i in np.random.randint(0, len(df[df.height > 100]), 5):\n",
    "    get_best_tpz(\n",
    "        df[df.height > 100].iloc[i].trace,\n",
    "        **kwfilt(kwdict, get_best_tpz),\n",
    "        debug_plots=True,\n",
    "        kwdict=kwdict\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b2279c",
   "metadata": {},
   "source": [
    "## Plot Trigger Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fea733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Apply File Timestamp to Event Time\"\"\"\n",
    "\n",
    "timestamps = df.fname.apply(lambda x: \"_\".join(x.split(\"_\")[-3:-1]))\n",
    "df[\"timestamp\"] = pd.to_datetime(timestamps, format=\"%Y-%m-%d_%H.%M.%S\")\n",
    "df[\"realtime\"] = pd.to_timedelta(df.time, unit=\"s\") + df[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot Realtime vs Height\"\"\"\n",
    "\n",
    "for channel in df.channel.unique():\n",
    "    fig, ax = plt.subplots(figsize=(8, 3), dpi=DPI_VIS, constrained_layout=True)\n",
    "    for fname in df[df.channel == channel].fname.unique():\n",
    "        data = df[(df.channel == channel) & (df.fname == fname)]\n",
    "        ax.scatter(data.realtime, data.height_mV, s=0.3, alpha=0.4, lw=0, label=fname)\n",
    "    ax.set(\n",
    "        xlabel=\"Realtime\",\n",
    "        ylabel=\"Height (mV)\",\n",
    "        title=f\"Channel {channel}\",\n",
    "        yscale=\"log\",\n",
    "    )\n",
    "    ax.tick_params(axis=\"x\", labelsize=8)\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17a87f",
   "metadata": {},
   "source": [
    "# Diagnose Scatter Weirdness\n",
    "\n",
    "No banding in scatter plot: what are the different regions?\n",
    "- Regions were likely me not doing PZ correction by accident (and other bugs)\n",
    "- Banding has been solved by getting at least 100k data points (before ~ 10k)\n",
    "\n",
    "Don't forget that each channel will be significantly different, so definitely isolate each individual channel before plotting/analyzing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8938d04",
   "metadata": {},
   "source": [
    "What to keep?\n",
    "\n",
    "Let's separate by time rather than each individual file.\n",
    "There's four regions seen in the plots above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "for channel in df.channel.unique():\n",
    "    nfs = len(df[df.channel == channel].fname.unique())\n",
    "    nrows = int(np.ceil(np.sqrt(nfs)))\n",
    "    ncols = int(np.ceil(nfs / nrows))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(30, 30) , dpi=300, constrained_layout=True)\n",
    "    for i, fname in enumerate(df[df.channel == channel].fname.unique()):\n",
    "        ax = axes.flat[i]\n",
    "        data = df[(df.channel == channel) & (df.fname == fname) & (df.multiplicity > 5)]\n",
    "        ax.scatter(data.height_mV, data.otherV, s=0.3, alpha=0.4, lw=0, label=fname)\n",
    "        ax.set(\n",
    "            xlabel=\"Height [mV]\",\n",
    "            ylabel=\"Other [$_\\\\sum$mV]\",\n",
    "            title=f\"{fname}\",\n",
    "        )\n",
    "        ax.title.set_fontsize(8)\n",
    "    # ax.scatter(\n",
    "    #     df[df.channel == channel].height_mV,\n",
    "    #     df[df.channel == channel].otherV,\n",
    "    #     s=0.3,\n",
    "    #     alpha=0.4,\n",
    "    #     lw=0,\n",
    "    # )\n",
    "    fig.suptitle(\n",
    "        \"Channel {channel}\",\n",
    "    )\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc1a68",
   "metadata": {},
   "source": [
    "For each time region, for each channel, plot height vs otherV\n",
    "\n",
    "The four time regions are:\n",
    "- Before 24-08-12 23:00\n",
    "- Between 24-08-12 23:00 and 24-08-13 2:00\n",
    "- Between 24-08-13 2:00 and 24-08-13 12:00\n",
    "- After 24-08-13 12:00\n",
    "\n",
    "The banding looks appropriate for each region. No need to perform cuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e96f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "\n",
    "time_regions = [\n",
    "    (\"Before 24-08-12 23:00\", df.realtime < \"2024-08-12 23:00\"),\n",
    "    (\"Between 24-08-12 23:00 and 24-08-13 2:00\", (df.realtime >= \"2024-08-12 23:00\") & (df.realtime < \"2024-08-13 02:00\")),\n",
    "    (\"Between 24-08-13 2:00 and 24-08-13 12:00\", (df.realtime >= \"2024-08-13 02:00\") & (df.realtime < \"2024-08-13 12:00\")),\n",
    "    (\"After 24-08-13 12:00\", df.realtime >= \"2024-08-13 12:00\"),\n",
    "]\n",
    "for channel in df.channel.unique():\n",
    "    for region_name, region_df in time_regions:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), dpi=DPI_VIS)\n",
    "        data = df[(df.channel == channel) & region_df]\n",
    "        ax.scatter(data.height_mV, data.otherV, s=0.3, alpha=0.4, lw=0)\n",
    "        ax.set(\n",
    "            xlabel=\"Height [mV]\",\n",
    "            ylabel=\"Other [$_\\\\sum$mV]\",\n",
    "            title=f\"Channel {channel} - {region_name}\",\n",
    "            xlim=(0, 25),\n",
    "            ylim=(0, 100),\n",
    "        )\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def50d6",
   "metadata": {},
   "source": [
    "Identify regions in scatter plot for plotting their traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "\n",
    "#: Low-Us High-Them region\n",
    "#: Red\n",
    "r1a, r1b, r1r = 100, 50, 5\n",
    "#: Zero-Us High-Them Region\n",
    "#: Green\n",
    "r2a, r2b, r2r = 0, 50, 5\n",
    "#: Low Both-Of-Us Region\n",
    "#: Blue\n",
    "r3a, r3b, r3r = 0, 20, 5\n",
    "#: Odd Bands above Low BothOfUs Region\n",
    "#: Yellow\n",
    "# r4a, r4b, r4r = 20, 50, 5\n",
    "#: Us Zero-Them Region\n",
    "#: Purple\n",
    "# r5a, r5b, r5r = 250, 5, 10\n",
    "#: Normal High-Them Lobe\n",
    "#: Cyan\n",
    "# r6a, r6b, r6r = 1000, 600, 50\n",
    "#: Higher-Us than Them Lobe\n",
    "#: Magenta\n",
    "# r7a, r7b, r7r = 2000, 900, 50\n",
    "\n",
    "\n",
    "def circle(x, y, x1, y1, r):\n",
    "    return (x - x1) ** 2 + (y - y1) ** 2 < r**2\n",
    "\n",
    "\n",
    "df[\"region1\"] = [circle(a, b, r1a, r1b, r1r) for a, b in zip(df.height, df.otherV)]\n",
    "df[\"region2\"] = [circle(a, b, r2a, r2b, r2r) for a, b in zip(df.height, df.otherV)]\n",
    "df[\"region3\"] = [circle(a, b, r3a, r3b, r3r) for a, b in zip(df.height, df.otherV)]\n",
    "# df[\"region4\"] = [circle(a, b, r4a, r4b, r4r) for a, b in zip(df.height, df.otherV)]\n",
    "# df[\"region5\"] = [circle(a, b, r5a, r5b, r5r) for a, b in zip(df.height, df.otherV)]\n",
    "# df[\"region6\"] = [circle(a, b, r6a, r6b, r6r) for a, b in zip(df.height, df.otherV)]\n",
    "# df[\"region7\"] = [circle(a, b, r7a, r7b, r7r) for a, b in zip(df.height, df.otherV)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), dpi=DPI_SV)\n",
    "colors = [\n",
    "    \"red\",\n",
    "    \"green\",\n",
    "    \"blue\",\n",
    "    # \"yellow\",\n",
    "    # \"purple\",\n",
    "    # \"cyan\",\n",
    "    # \"magenta\"\n",
    "]\n",
    "rdesc = [\n",
    "    \"Low-Us High-Them\",\n",
    "    \"Zero-Us High-Them\",\n",
    "    \"Low Both-Of-Us\",\n",
    "    # \"Odd Bands above Low Both-Of-Us\",\n",
    "    # \"Us Zero-Them\",\n",
    "    # \"Normal High-Them Lobe\",\n",
    "    # \"Higher-Us than Them Lobe\",\n",
    "]\n",
    "ax.scatter(df.height, df.otherV, s=0.1, alpha=0.2, lw=0)\n",
    "for region in [\n",
    "    \"region1\",\n",
    "    \"region2\",\n",
    "    \"region3\",\n",
    "    # \"region4\",\n",
    "    # \"region5\",\n",
    "    # \"region6\",\n",
    "    # \"region7\",\n",
    "]:\n",
    "    ax.scatter(\n",
    "        df.height[df[region]],\n",
    "        df.otherV[df[region]],\n",
    "        s=0.1,\n",
    "        alpha=0.5,\n",
    "        c=colors.pop(0),\n",
    "        lw=0,\n",
    "        label=region,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496f843",
   "metadata": {},
   "source": [
    "Plot Trace waveforms and Average Trace for Selected Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%\n",
    "\n",
    "for region in [\n",
    "    \"region1\",\n",
    "    \"region2\",\n",
    "    \"region3\",\n",
    "    # \"region4\",\n",
    "    # \"region5\",\n",
    "    # \"region6\",\n",
    "    # \"region7\",\n",
    "]:\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=200)\n",
    "    [\n",
    "        ax.plot(trc, lw=0.5, alpha=1)\n",
    "        for trc in df.trace[df[region]].sample(frac=50 / 2000)\n",
    "    ]\n",
    "    ax.plot(\n",
    "        np.mean(df.trace[df[region]], axis=0),\n",
    "        lw=2,\n",
    "        alpha=1,\n",
    "        c=\"w\",\n",
    "    )\n",
    "    ax.set(title=f\"Region {region[-1]} Pulses (Us)\\n{rdesc[int(region[-1]) - 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126bbcf8",
   "metadata": {},
   "source": [
    "## Finally Apply Laser Heating Calibration\n",
    "\n",
    "Turns out the multiplicity cut is bad: data with multiplicity down to even 2 contains some laser data. Cutting that off prematurely produces the shelf I've seen in a couple spectrum plots. Therefore it is optimal to treat all data as potentially laser data.\n",
    "\n",
    "Luckily, a correction based on otherV won't affect nuclear data nearly at all because the otherV during a nuclear event will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beest.laser import correct_substrate_heating, deskewFFT, argmax_part\n",
    "from beest.plot import ScatterHistogramPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4eef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boop(df, channel):\n",
    "    data = df[(df.channel == channel)]\n",
    "    corrected_values = correct_substrate_heating(\n",
    "        data.height_mV, data.sumV, dev_plot=True, dev_name=f\"ch{channel}\"\n",
    "    )\n",
    "    return data.index, corrected_values\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=4)(\n",
    "    delayed(boop)(df, channel) for channel in df.channel.unique()\n",
    ")\n",
    "# results = [boop(df, channel) for channel in df.channel.unique()]\n",
    "\n",
    "df.drop(\"correct\", inplace=True, axis=1)\n",
    "results = [r for r in results if r is not None]\n",
    "for indices, corrected_values in results:\n",
    "    df.loc[indices, \"correct\"] = corrected_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913bdceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(\"out/processed/240812-corrected.h5\", key=\"data\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b9153",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in df.channel.unique():\n",
    "    data = df[(df.channel == channel)]\n",
    "    xmin, xmax = np.percentile(data.correct, [1, 99])\n",
    "    ymin, ymax = np.percentile(data.otherV, [1, 99])\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5), dpi=200, constrained_layout=True)\n",
    "    axs[0].scatter(data.correct, data.otherV, s=0.1, alpha=0.5, lw=0)\n",
    "    axs[0].set(\n",
    "        xlabel=\"Corrected Height [mV]\",\n",
    "        ylabel=\"OtherV [$_\\\\sum$mV]\",\n",
    "        title=f\"Channel {channel}\",\n",
    "        xlim=(xmin, xmax),\n",
    "        ylim=(ymin, ymax),\n",
    "    )\n",
    "    h, b = np.histogram(data.correct, bins=5000)\n",
    "    axs[1].step(b[:-1], h)\n",
    "    axs[1].set(\n",
    "        xlabel=\"Corrected Height [mV]\",\n",
    "        ylabel=\"Counts\",\n",
    "        title=f\"Channel {channel}\",\n",
    "        yscale=\"log\",\n",
    "        xlim=(xmin, xmax),\n",
    "    )\n",
    "\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c149f",
   "metadata": {},
   "source": [
    "## Debug Correction\n",
    "\n",
    "I think the problem was manifold.\n",
    "- The Al data is low amplitude so it's important to set the FFT parameters quite near the expected values\n",
    "- I was using mV (> 1) vs V (0 < X < 1) which made the existing code unstable. Turns out bin number is exchangeable with bin width when FFTing values less than 1\n",
    "\n",
    "The code is now extremely robust\n",
    "- It uses actual frequencies rather than bin values to give the FFT frequency a meaning (1/mV) which is directly attributable to the peak spacing\n",
    "- It uses percentiles to zone in on the data of import rather than hard coded ranges which differ per detector and probably per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ccca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0\n",
    "slice_max = 0.025\n",
    "numLines = 20\n",
    "firstLine = 7\n",
    "dev_plot = True\n",
    "dev_name = \"dev\"\n",
    "\n",
    "# data = df[(df.channel == channel)]\n",
    "data = df[(df.channel == channel) & (df.multiplicity > 5)]\n",
    "correct = correct_substrate_heating(\n",
    "    data.height_mV, data.sumV, dev_plot=True, dev_name=f\"ch{channel}\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=DPI_VIS)\n",
    "ax.scatter(\n",
    "    correct,\n",
    "    data.otherV,\n",
    "    s=0.3,\n",
    "    alpha=0.4,\n",
    "    lw=0,\n",
    ")\n",
    "ax.set(\n",
    "    xlabel=\"Height [mV]\",\n",
    "    ylabel=\"Sum [$_\\\\sum$mV]\",\n",
    "    title=f\"Channel {channel}\",\n",
    "    xlim=(0, 25),\n",
    "    ylim=(0, 100),\n",
    ")\n",
    "ax.axvline(3, c=\"r\", ymin=0.4, lw=1, alpha=0.5)\n",
    "ax.axvline(3, c=\"r\", ymax=0.1, lw=1, alpha=0.5)\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565fe52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0\n",
    "slice_max = 0.025\n",
    "numLines = 20\n",
    "firstLine = 7\n",
    "dev_plot = True\n",
    "dev_name = \"dev\"\n",
    "\n",
    "data = df[(df.channel == channel)]\n",
    "correct = correct_substrate_heating(\n",
    "    data.height_mV, data.sumV, dev_plot=True, dev_name=f\"ch{channel}\"\n",
    ")\n",
    "pulseV_laser = correct\n",
    "sum_heights = data.sumV\n",
    "pulseV_laser_other = sum_heights - pulseV_laser.astype(np.float32)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=DPI_VIS)\n",
    "ax.scatter(\n",
    "    pulseV_laser,\n",
    "    data.otherV,\n",
    "    s=0.3,\n",
    "    alpha=0.4,\n",
    "    lw=0,\n",
    ")\n",
    "ax.set(\n",
    "    xlabel=\"Height [mV]\",\n",
    "    ylabel=\"Sum [$_\\\\sum$mV]\",\n",
    "    title=f\"Channel {channel}\",\n",
    "    xlim=(0, 25),\n",
    "    ylim=(0, 100),\n",
    ")\n",
    "ax.axvline(3, c=\"r\", ymin=0.4, lw=1, alpha=0.5)\n",
    "ax.axvline(3, c=\"r\", ymax=0.1, lw=1, alpha=0.5)\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290917c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: TODO Should deskewFFT take all entries to preserve column shape?\n",
    "freqmaxFFT, maxFFT, angmaxFFT, gradients = deskewFFT(pulseV_laser, pulseV_laser_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc40ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / freqmaxFFT[np.argmax(maxFFT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95456067",
   "metadata": {},
   "source": [
    "The FFT works!! We see a clear peak in the gradient testing and the slices do in fact fit to linear approximations of the banding for a second order correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: Axes flipped to seek flat lines rather than vertical ones\n",
    "xs = pulseV_laser_other\n",
    "ys = pulseV_laser - pulseV_laser_other * gradients[np.argmax(maxFFT)]\n",
    "\n",
    "\n",
    "#: Limits via percentile\n",
    "xmin, xmax = np.percentile(xs, [5, 95])\n",
    "ymin, ymax = np.percentile(ys, [10, 80])\n",
    "\n",
    "#: Angmax may vary from -pi to pi, but its basis is still 2pi\n",
    "offset = angmaxFFT[np.argmax(maxFFT)] / 2 / np.pi\n",
    "\n",
    "sliceEdges = np.arange(\n",
    "    #: Offset is located at the peak heights, slice between peaks with 0.5\n",
    "    (0.5 + offset) / freqmaxFFT[np.argmax(maxFFT)],\n",
    "    ymax,\n",
    "    1 / freqmaxFFT[np.argmax(maxFFT)],\n",
    ")\n",
    "\n",
    "#: Cull lines below ymin\n",
    "sliceEdges = sliceEdges[sliceEdges > ymin]\n",
    "\n",
    "corrections = np.zeros(len(sliceEdges), dtype=float)\n",
    "\n",
    "if dev_plot:\n",
    "    plt.plot(gradients, maxFFT)\n",
    "    plt.xlabel(\"Gradient\")\n",
    "    plt.ylabel(\"Max FFT\")\n",
    "    plt.title(f\"Max FFT\\ngradient: {gradients[np.argmax(maxFFT)]}\")\n",
    "    display(plt.gcf())\n",
    "    plt.close()\n",
    "    # plt.savefig(f\"dev/{dev_name}-maxfft.jpeg\")\n",
    "for i, ymini in enumerate(sliceEdges):\n",
    "    ymaxi = sliceEdges[i + 1] if i + 1 < len(sliceEdges) else ymax\n",
    "    cutoutx = (pulseV_laser_other < xmax) & (pulseV_laser_other > xmin)\n",
    "    cutouty = (ymini < ys) & (ymaxi > ys)\n",
    "    cutout = cutoutx & cutouty\n",
    "    try:\n",
    "        poly = np.poly1d(np.polyfit(xs[cutout], ys[cutout], 1))\n",
    "    except TypeError:\n",
    "        continue\n",
    "    if dev_plot:\n",
    "        plt.plot([xmin, xmax], poly([xmin, xmax]), color=\"orange\")\n",
    "        pass\n",
    "#     corrections[i] = poly[1]\n",
    "if dev_plot:\n",
    "    plt.scatter(xs, ys, s=0.1, alpha=0.4, lw=0)\n",
    "\n",
    "    # Find the range where 90% of the data lie in X and Y\n",
    "    x_min, x_max = np.percentile(xs, [5, 95])\n",
    "    y_min, y_max = np.percentile(ys, [5, 95])\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "    # plt.savefig(f\"dev/{dev_name}-slices.jpeg\")\n",
    "    display(plt.gcf())\n",
    "    plt.close()\n",
    "avg_correction = np.average(corrections)\n",
    "true_grad = gradients[np.argmax(maxFFT)] + avg_correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6006ad2",
   "metadata": {},
   "source": [
    "Turns out it's better to have LOTS of bins and zoom in closely to the low-frequency side. This makes sense but it's weird that the degree of bin granularity isn't what improves FFT resolution or accuracy in detecting periodicity but rather the simple expanse transformed, even if the values in those bins are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc28fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = int(1e5)\n",
    "bestG = 0.021\n",
    "\n",
    "xs = pulseV_laser - pulseV_laser_other * bestG\n",
    "ys = pulseV_laser_other\n",
    "\n",
    "xmin, xmax = np.percentile(xs, [5, 95])\n",
    "xMin, xMax = np.min(xs), np.max(xs)\n",
    "range = [xMin, xMax]\n",
    "\n",
    "h, b = np.histogram(xs, range=range, bins=bins)\n",
    "fft = np.fft.rfft(h - np.mean(h), norm=\"ortho\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=DPI_VIS)\n",
    "ax.scatter(xs, ys, s=0.3, alpha=0.4, lw=0)\n",
    "ax.set(\n",
    "    xlabel=\"Height [mV]\",\n",
    "    ylabel=\"Sum [$_\\\\sum$mV]\",\n",
    "    title=f\"Channel {channel}\",\n",
    "    xlim=range,\n",
    "    ylim=(0, 100),\n",
    ")\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=DPI_VIS)\n",
    "plt.step(b[:-1], h, where=\"post\", lw=0.05)\n",
    "plt.gca().set(xlabel=\"Height corrected\", ylabel=\"Counts\", xlim=range, yscale=\"log\")\n",
    "display(plt.gcf())\n",
    "plt.close()\n",
    "\n",
    "fftfreq = np.fft.rfftfreq(bins, d=np.diff(range) / bins)\n",
    "plt.figure(figsize=(10, 6), dpi=DPI_VIS)\n",
    "plt.plot(fftfreq, np.abs(fft))\n",
    "plt.gca().set(yscale=\"log\", xlim=(-5, 20))\n",
    "display(plt.gcf())\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "pulseHeight = pulseV_laser\n",
    "otherHeight = pulseV_laser_other\n",
    "gradientRange = (-0.040, 0.040, 0.0005)\n",
    "mVmin = 1.1\n",
    "\n",
    "xmin, xmax = np.percentile(pulseHeight, [5, 95])\n",
    "\n",
    "# fmt: off\n",
    "gradients = np.arange(*gradientRange, dtype=np.float32)\n",
    "maxFFT    = np.zeros_like(gradients,  dtype=np.float32)\n",
    "angmaxFFT = np.zeros_like(gradients,  dtype=np.float32)\n",
    "freqmaxFFT = np.zeros_like(gradients,  dtype=np.float32)\n",
    "# fmt: on\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=DPI_VIS)\n",
    "for i, grad in list(enumerate(gradients)):\n",
    "    xs = pulseHeight - otherHeight * grad\n",
    "    range = [np.min(xs), np.max(xs)]\n",
    "    h, _ = np.histogram(xs, range=range, bins=bins)\n",
    "    fft = np.fft.rfft(h - np.mean(h), norm=\"ortho\")\n",
    "    #: Calculate x-axis (frequency in per mV (pulse height) units)\n",
    "    #: d is units of pulse height (mV) per bin\n",
    "    fftfreq = np.fft.rfftfreq(bins, d=np.diff(range) / bins)\n",
    "    plt.plot(fftfreq, np.abs(fft))\n",
    "    plt.gca().set(yscale=\"log\")\n",
    "    argmaxFFT = argmax_part(np.abs(fft), fftfreq > mVmin)\n",
    "    freqmaxFFT[i] = fftfreq[argmaxFFT]\n",
    "    maxFFT[i] = np.abs(fft)[argmaxFFT]\n",
    "    angmaxFFT[i] = np.angle(fft[argmaxFFT])\n",
    "plt.gca().set(xlabel=\"Frequency\", ylabel=\"FFT\", xlim=(0, 3))\n",
    "plt.axhline(max(maxFFT))\n",
    "plt.axvline(freqmaxFFT[np.argmax(maxFFT)])\n",
    "display(plt.gcf())\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dabeef",
   "metadata": {},
   "source": [
    "A close-up of the FFT near the periodicity bump using the correct units of frequency on the x-axis. This gets us the ~1.6 value we expect by eye looking at the scatter above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = int(1e5)\n",
    "bestG = 0.021\n",
    "plt.figure(figsize=(10, 6), dpi=DPI_VIS)\n",
    "for g in np.arange(0, 0.03, 0.001):\n",
    "    h, _ = np.histogram(\n",
    "        pulseV_laser - pulseV_laser_other * g, range=[xmin, xmax], bins=bins\n",
    "    )\n",
    "    fft = np.fft.rfft(h - np.mean(h), norm=\"ortho\")\n",
    "\n",
    "    #: FFT frequency units in inverse binwidth (mV)\n",
    "    maxV = np.max(pulseV_laser - pulseV_laser_other * g)\n",
    "    fftfreq = np.fft.rfftfreq(bins, d=(xmax - xmin) / bins)\n",
    "    plt.plot(fftfreq, np.abs(fft))\n",
    "    plt.gca().set(yscale=\"log\")\n",
    "plt.gca().set(xlabel=\"Frequency\", ylabel=\"FFT\", xlim=(0, 5))\n",
    "display(plt.gcf())\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad75995",
   "metadata": {},
   "source": [
    "## Finished Debugging DeskewFFT\n",
    "\n",
    "The old version was getting lucky assuming that the bin number of the frequency maximum corresponded to the inverse frequency in mV units. Likely it could do this because the range of the FFT was from 0 to 1. For real unit FFT, one needs to use `np.fftfreq` and understand that the \"frequency\" is in units of pulse height (here mV).\n",
    "\n",
    "I updated `deskewFFT` to pass the freqmaxFFT rather than the argmaxFFT which is in units of mV (generally pulse height). The minimum in the FFT where we look for periodicity is also now in units of the pulse height. This should generally be consistent across detectors so long as we understand what the typical pulse height of a laser signal is for that detector. At our resolutions this is greater than a single mV depending on the responsivity.\n",
    "\n",
    "Before COMITTING, cleaning up, and moving on, let me validate that deskewFFT works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9208dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_part(array, condition):\n",
    "    \"\"\"Return the max position of an array given a condition filters the array.\n",
    "    The position is in the full array despite the condition possibly being a subset.\n",
    "    \"\"\"\n",
    "    #: Where returns indices where the condition is true, then argmax finds the max index in the same subset\n",
    "    return np.where(condition)[0][np.argmax(array[condition])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ecb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = pulseV_laser_other\n",
    "ys = pulseV_laser - pulseV_laser_other * bestG\n",
    "freqmaxFFT = argmax_part(np.abs(fft), fftfreq > 0.3)  #: The low Freq bump\n",
    "# argmaxFFT = argmax_part(np.abs(fft), fftfreq > 1) #: The probably right one\n",
    "angmaxFFT = np.angle(fft[freqmaxFFT])\n",
    "\n",
    "#: Limits via percentile\n",
    "xmin, xmax = np.percentile(xs, [5, 95])\n",
    "ymin, ymax = np.percentile(ys, [10, 80])\n",
    "\n",
    "#: Angmax may vary from -pi to pi, but its basis is still 2pi\n",
    "offset = angmaxFFT / 2 / np.pi\n",
    "\n",
    "sliceEdges = np.arange(\n",
    "    #: Offset is located at the peak heights, slice between peaks with 0.5\n",
    "    (0.5 + offset) / fftfreq[freqmaxFFT],\n",
    "    ymax,\n",
    "    1 / fftfreq[freqmaxFFT],\n",
    ")\n",
    "\n",
    "#: Cull lines below ymin\n",
    "sliceEdges = sliceEdges[sliceEdges > ymin]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=DPI_VIS)\n",
    "ax.scatter(xs, ys, s=0.3, alpha=0.4, lw=0)\n",
    "ax.set(\n",
    "    ylabel=\"Height [mV]\",\n",
    "    xlabel=\"Other [$_\\\\sum$mV]\",\n",
    "    title=f\"Channel {channel}\",\n",
    "    xlim=(0, 100),\n",
    "    ylim=(0, 15),\n",
    ")\n",
    "for i, ymini in enumerate(sliceEdges):\n",
    "    ax.axhline(y=ymini, xmin=0.5, color=\"orange\", alpha=0.4)\n",
    "    pass\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73beec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deskewFFT(pulseV_laser, pulseV_laser_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a49638",
   "metadata": {},
   "source": [
    "### (On Hold) Periodicity Discovery\n",
    "\n",
    "Background won't be periodic like laser data will, so we should be able to discover laser events based on periodicity.\n",
    "But, I can't make sense of the FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.multiplicity.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the time differences between consecutive events\n",
    "event_times = df[df.multiplicity > 5].time\n",
    "time_diffs = np.diff(event_times)\n",
    "# time_diffs = time_diffs[time_diffs.nonzero()[0]]\n",
    "N = len(time_diffs)\n",
    "\n",
    "# Apply FFT to the time differences\n",
    "yf = np.fft.fft(time_diffs - np.mean(time_diffs), norm=\"ortho\")\n",
    "xf = np.fft.fftfreq(N, d=2e-8)\n",
    "\n",
    "# Find the most significant frequency\n",
    "idx = np.argmax(np.abs(yf[: N // 4]))\n",
    "dominant_freq = xf[idx]\n",
    "\n",
    "# Calculate the most periodic time interval\n",
    "period = 1 / dominant_freq\n",
    "\n",
    "print(f\"The most periodic time interval is approximately {period*1e9} nanoseconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d639046",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(\n",
    "    xf,\n",
    "    np.abs(yf),\n",
    "    # s=1,\n",
    "    # lw=0,\n",
    ")\n",
    "ax.scatter([xf[idx]], [np.abs(yf[idx])], c=\"r\", s=10, zorder=2)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlim(0, 1e7)\n",
    "ax.set_ylim(1e-6, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f988b",
   "metadata": {},
   "source": [
    "#### Modulo\n",
    "\n",
    "Event Time vs Modulo_100 $\\pm$ something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5620f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#: Event Time vs Modulo 100 ms Plus/Minus Steps up to 50 ms\n",
    "# df[\"ig_laser\"] =\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=250)\n",
    "data = df[(df.channel == channel) & (df.fname == df.fname.unique()[0])]\n",
    "ax.scatter(data.time, data.time % 0.001, s=0.1, lw=0)\n",
    "# ax.plot(df.time, (df.time % 0.1).rolling(1000).median(), lw=1, c=\"r\")\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# df[\"ig_laser\"] = np.abs(\n",
    "#     (df.time % 0.05) - (df.time % 0.05).rolling(1000).median()\n",
    "# ) < 0.005 * np.mean(df.time % 0.05)\n",
    "# ax.scatter(df.time[df.ig_laser], df.time[df.ig_laser] % 0.05, s=0.1, lw=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392aca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=200)\n",
    "df.height[df.ig_laser].hist(bins=1000, histtype=\"step\", lw=1, color=\"r\", ax=ax)\n",
    "ax.set(yscale=\"log\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=200)\n",
    "h, e = np.histogram(df.height_mV[~df.ig_laser], bins=np.arange(0, 25, 0.1))\n",
    "ax.step(e[:-1], h, lw=1, color=\"b\")\n",
    "ax.set(yscale=\"log\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=200)\n",
    "ax.scatter(df[~df.ig_laser].time, df[~df.ig_laser].height_mV, s=0.1, lw=0, color=\"b\")\n",
    "ax.set(yscale=\"log\", xlim=(0, 50e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=200)\n",
    "for file in df.fname.unique():\n",
    "    d = df[(df.fname == file) & (df.ig_laser)]\n",
    "    ax.scatter(d.height_mV, d.otherV, s=0.1, lw=0, alpha=0.1, label=file)\n",
    "ax.legend(\n",
    "    loc=\"upper right\",\n",
    "    fontsize=8,\n",
    "    # title=\"File\",\n",
    "    # title_fontsize=8,\n",
    "    # shadow=True,\n",
    "    # fancybox=True,\n",
    "    # frameon=True,\n",
    "    # framealpha=0.5,\n",
    "    # edgecolor=\"black\",\n",
    "    # facecolor=\"white\",\n",
    "    ncol=2,\n",
    "    markerscale=10,\n",
    "    scatterpoints=10,\n",
    "    # handletextpad=0.1,\n",
    "    # handlelength=0.5,\n",
    "    # handleheight=0.5,\n",
    "    # borderpad=0.1,\n",
    "    # labelspacing=0.1,\n",
    "    # columnspacing=0.1,\n",
    "    # numpoints=1,\n",
    "    # mode=\"expand\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    # bbox_transform=None,\n",
    "    # handler_map=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb43e3a",
   "metadata": {},
   "source": [
    "# Exploring Other Files\n",
    "\n",
    "Maybe I just have bad data in the file I'm working with. Let's explore all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    d: sum([os.path.getsize(x) for x in glob.glob(os.path.join(d, \"*.bin\"))])\n",
    "    / 1024\n",
    "    / 1024\n",
    "    / 1024\n",
    "    for d in set([os.path.dirname(f) for f in files])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e79269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "total = 0\n",
    "for file in [file for file in files if \"20240806\" in os.path.dirname(file)]:\n",
    "    dfi, header, _ = load_and_process(file, multithread=True)\n",
    "    print(f\"Size: {os.path.getsize(file) / 1024 / 1024 / 1024} GB\")\n",
    "    if len(dfi) == 0:\n",
    "        print(f\"Skipping {file}\")\n",
    "        continue\n",
    "    dfi[\"ig_laser\"] = np.abs(\n",
    "        (dfi.time % 0.1)\n",
    "        - (dfi.time % 0.1).rolling(min([1000, int(0.01 * len(dfi))])).median()\n",
    "    ) < 0.01 * np.mean(dfi.time % 0.1)\n",
    "    dfi[\"fname\"] = os.path.basename(file)\n",
    "    total += os.path.getsize(file)\n",
    "    print(f\"Loaded Size: {total / 1024 / 1024 / 1024} GB\")\n",
    "    df = pd.concat([df, dfi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf72f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    df, _, _ = load_and_process(file, multithread=False)\n",
    "    if len(df) == 0:\n",
    "        print(f\"Skipping {file}\")\n",
    "        continue\n",
    "    df[\"ig_laser\"] = np.abs(\n",
    "        (df.time % 0.1)\n",
    "        - (df.time % 0.1).rolling(min([1000, int(0.01 * len(df))])).median()\n",
    "    ) < 0.01 * np.mean(df.time % 0.1)\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=200)\n",
    "    df[df.ig_laser].plot(x=\"height_mV\", y=\"otherV\", kind=\"scatter\", s=0.1, lw=0, ax=ax)\n",
    "    plt.pause(0.1)\n",
    "    plt.close()\n",
    "    if len(df[df.ig_laser]) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), dpi=200)\n",
    "        [\n",
    "            ax.plot(trc, alpha=0.1)\n",
    "            for trc in df.trace[df.ig_laser].sample(\n",
    "                n=min([50, int(0.01 * len(df[df.ig_laser]))])\n",
    "            )\n",
    "        ]\n",
    "        plt.pause(0.1)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf3a1b3",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b361e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in df.channel.unique():\n",
    "    key = f\"data_channel{channel}\"\n",
    "    df[df.channel == channel].to_hdf(\n",
    "        f\"../../out/{os.path.basename(dev_file)}.h5\", key=key\n",
    "    )\n",
    "    header[\"channel\"] = channel\n",
    "    pd.Series(header).to_hdf(\n",
    "        f\"../../out/{os.path.basename(dev_file)}.h5\", key=f\"meta{key}\", mode=\"w\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05c55d",
   "metadata": {},
   "source": [
    "## Run Calibration Script\n",
    "\n",
    "First try tagging mode then try calibration mode.\n",
    "\n",
    "May need `-e 4` for setting calibration energy to new mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../scripts/laser_heating_calibration.py\" -d \"../../out/listmode_11_card_0_UTC_2024-07-23_11.14.23_chunk76.bin.h5\" -m tagging -e 4 -c 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bef6696",
   "metadata": {},
   "source": [
    "#### Dev: Did It Work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67af8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_hdf(f\"../../out/{os.path.basename(dev_file)}.h5\", key=f\"data_channel0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcca9a56",
   "metadata": {},
   "source": [
    "# --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in sorted(df.channel.unique()):\n",
    "    fig, ax = plt.subplots(figsize=(8, 4.5), dpi=100)\n",
    "\n",
    "    h, e = np.histogram(df[df.channel == channel].height, bins=1000)\n",
    "\n",
    "    ax.step(e[:-1], h)\n",
    "\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Multiplicity (ch {channel})\\n{dev_file.split('/')[-4:-2]}\")\n",
    "    ax.set_xlabel(\"Height\")\n",
    "    # ax.set_xlim(0, 500)\n",
    "    ax.set_ylabel(\"Counts\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0796ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in sorted(df.channel.unique()):\n",
    "    fig, ax = plt.subplots(figsize=(8, 4.5), dpi=100)\n",
    "\n",
    "    h, e = np.histogram(df[df.channel == channel].height, bins=1000)\n",
    "\n",
    "    ax.step(e[:-1], h)\n",
    "\n",
    "    for mult in sorted(df[df.channel == channel].multiplicity.unique()):\n",
    "        if mult == 1:\n",
    "            continue\n",
    "        h, _ = np.histogram(\n",
    "            df[df.multiplicity == mult][df.channel == channel].height, bins=e\n",
    "        )\n",
    "        ax.step(e[:-1], h, label=f\"Multiplicity {mult}\")\n",
    "\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Multiplicity (ch {channel})\\n{dev_file.split('/')[-4:-2]}\")\n",
    "    ax.set_xlabel(\"Height\")\n",
    "    ax.set_xlim(0, 500)\n",
    "    ax.set_ylabel(\"Counts\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e255c-9a52-462e-9ad5-d4adca23f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 28\n",
    "\n",
    "micro_df = df[df[\"channel\"] == channel]\n",
    "max_sumV = max(micro_df[\"sumV\"])\n",
    "filt = micro_df[(micro_df[\"otherV\"] < 2000) & (micro_df[\"multiplicity\"] >= 2)]\n",
    "data = filt[\"height_mV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaec8ca-9713-4cb7-b7a9-cfa36a33f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "\n",
    "nBins = 300\n",
    "hRange = (0, 90)\n",
    "\n",
    "counts, edges = np.histogram(data, bins=nBins, range=hRange)\n",
    "max_bin_index = np.argmax(counts)\n",
    "max_bin_value = edges[max_bin_index]\n",
    "\n",
    "counts, bin_edges, _ = plt.hist(data, bins=nBins, range=hRange, histtype=\"step\")\n",
    "\n",
    "bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "plt.title(f\"Peak Amplitude Voltage Spectrum, Channel {channel}\")\n",
    "plt.xlabel(\"Millivolts\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.tight_layout()\n",
    "plt.xlim(hRange)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e675253-80dc-47e5-8e56-3a6bebd6a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in df1[\"channel\"].unique():\n",
    "\n",
    "    micro_df_a = df1[df1[\"channel\"] == channel]\n",
    "    micro_df_b = df2[df2[\"channel\"] == channel]\n",
    "    micro_df_c = df3[df3[\"channel\"] == channel]\n",
    "    micro_df_d = df4[df4[\"channel\"] == channel]\n",
    "\n",
    "    micro_df = pd.concat(\n",
    "        [micro_df_a, micro_df_b, micro_df_c, micro_df_d], ignore_index=True\n",
    "    )\n",
    "\n",
    "    max_sumV = max(micro_df[\"sumV\"])\n",
    "    filt = micro_df[(micro_df[\"otherV\"] < 2000) & (micro_df[\"multiplicity\"] >= 2)]\n",
    "    data = filt[\"height_mV\"]\n",
    "\n",
    "    plt.figure(figsize=(9, 5))\n",
    "\n",
    "    nBins = 500\n",
    "    hRange = (0, 100)\n",
    "\n",
    "    counts, edges = np.histogram(data, bins=nBins, range=hRange)\n",
    "    max_bin_index = np.argmax(counts)\n",
    "    max_bin_value = edges[max_bin_index]\n",
    "\n",
    "    counts, bin_edges, _ = plt.hist(data, bins=nBins, range=hRange, histtype=\"step\")\n",
    "\n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "    plt.title(f\"Peak Amplitude Voltage Spectrum, Channel {channel}\")\n",
    "    plt.xlabel(\"Millivolts\")\n",
    "    plt.ylabel(\"Counts [0.2/mV]\")\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(hRange)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b985d0-d892-4196-be46-a6b35b1ac8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, h1, ktpz = load_and_process(files[0])\n",
    "df1.drop(\"trace\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d957f5-4a91-47f6-82db-35bd5ec9477a",
   "metadata": {},
   "source": [
    "# Super long overnight processing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c32be-a453-48ea-a8ac-6ab93f36fdb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel = 28\n",
    "\n",
    "# save_file = \"20241010_processed_uncleaned2.csv\"\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    print(\"/n----------------------------\")\n",
    "    print(f\"Processing file {i} of {len(files)}\")\n",
    "    if i == 0:\n",
    "        print(\"skipping seed file\")\n",
    "    else:\n",
    "        df, _, _ = load_and_process(file, known_tpz=ktpz)\n",
    "        df.drop(\"trace\", axis=1, inplace=True)\n",
    "        df1 = pd.concat([df1, df], ignore_index=True)\n",
    "\n",
    "    print(df1)\n",
    "    # save progress\n",
    "    #    df1.to_csv(save_file, mode='w', index=False)\n",
    "    # plot\n",
    "\n",
    "    micro_df = df1[df1[\"channel\"] == channel]\n",
    "\n",
    "    max_sumV = max(micro_df[\"sumV\"])\n",
    "    filt = micro_df[(micro_df[\"otherV\"] < 2000) & (micro_df[\"multiplicity\"] >= 2)]\n",
    "    data = filt[\"height_mV\"]\n",
    "\n",
    "    plt.figure(figsize=(9, 5))\n",
    "\n",
    "    nBins = 500\n",
    "    hRange = (0, 100)\n",
    "\n",
    "    counts, edges = np.histogram(data, bins=nBins, range=hRange)\n",
    "    max_bin_index = np.argmax(counts)\n",
    "    max_bin_value = edges[max_bin_index]\n",
    "\n",
    "    counts, bin_edges, _ = plt.hist(data, bins=nBins, range=hRange, histtype=\"step\")\n",
    "\n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "    plt.title(f\"Voltage Spectrum, Channel {channel}, ~{20000*(i+1)} counts\")\n",
    "    plt.xlabel(\"Voltage [mV]\")\n",
    "    plt.ylabel(\"Counts [0.2/mV]\")\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(hRange)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0466fc-e0cc-42d6-939e-cad5b17ec7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"20241010_processed_uncleaned.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fe340d-58ac-4e73-8338-c04b6e32da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in df1[\"channel\"].unique():\n",
    "\n",
    "    micro_df = df1[df1[\"channel\"] == channel]\n",
    "\n",
    "    max_sumV = max(micro_df[\"sumV\"])\n",
    "    filt = micro_df[\n",
    "        (micro_df[\"otherV\"] < 2000) & (micro_df[\"multiplicity\"] >= 3)\n",
    "    ]  # we dont want multiplicty 2\n",
    "    filt2 = micro_df[(micro_df[\"otherV\"] < 2000) & (micro_df[\"multiplicity\"] == 1)]\n",
    "    data = filt[\"height_mV\"]\n",
    "    data2 = filt2[\"height_mV\"]\n",
    "\n",
    "    plt.figure(figsize=(9, 5))\n",
    "\n",
    "    nBins = 500\n",
    "    hRange = (0, 100)\n",
    "\n",
    "    counts, edges = np.histogram(data, bins=nBins, range=hRange)\n",
    "    max_bin_index = np.argmax(counts)\n",
    "    max_bin_value = edges[max_bin_index]\n",
    "\n",
    "    counts, bin_edges, _ = plt.hist(data, bins=nBins, range=hRange, histtype=\"step\")\n",
    "    plt.hist(data2, bins=nBins, range=hRange, histtype=\"step\", color=\"red\")\n",
    "\n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "    plt.title(f\"Peak Amplitude Voltage Spectrum, Channel {channel}\")\n",
    "    plt.xlabel(\"Millivolts\")\n",
    "    plt.ylabel(\"[Counts/0.2mV]\")\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(hRange)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed280741-2bc4-460c-bab2-218a9e61e52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cecce5-2f1e-48a4-9a52-bbb1736ae56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, A, mu, sigma):\n",
    "    return A * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n",
    "\n",
    "\n",
    "# Function to fit Gaussian to a peak and return centroid and error\n",
    "def fit_gaussian_to_peak(x_data, y_data, peak_index, window=10):\n",
    "    # Select a slice around the peak\n",
    "    start = max(peak_index - window // 2, 0)\n",
    "    end = min(peak_index + window // 2, len(x_data))\n",
    "    x_slice = x_data[start:end]\n",
    "    y_slice = y_data[start:end]\n",
    "\n",
    "    # Initial guess: A = max(y), mu = x at peak, sigma = small guess\n",
    "    initial_guesses = [max(y_slice), x_data[peak_index], 1.0]\n",
    "\n",
    "    try:\n",
    "        # Fit Gaussian to the data slice\n",
    "        params, covariance = curve_fit(gaussian, x_slice, y_slice, p0=initial_guesses)\n",
    "        # Centroid is mu, error on centroid is sqrt(covariance on mu)\n",
    "        centroid = params[1]\n",
    "        centroid_error = np.sqrt(covariance[1, 1])\n",
    "\n",
    "        # Extract sigma and its error\n",
    "        sigma = params[2]\n",
    "        sigma_error = np.sqrt(\n",
    "            covariance[2, 2]\n",
    "        )  # sigma error is the square root of the diagonal element\n",
    "\n",
    "        return centroid, centroid_error, sigma, sigma_error, params\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting peak at index {peak_index}: {e}\")\n",
    "        return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f1931-628e-4d87-8275-ce09d9cfee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 28\n",
    "\n",
    "micro_df = df1[df1[\"channel\"] == channel]\n",
    "max_sumV = max(micro_df[\"sumV\"])\n",
    "filt = micro_df[(micro_df[\"otherV\"] < 10000) & (micro_df[\"multiplicity\"] >= 2)]\n",
    "data = filt[\"height_mV\"]\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "\n",
    "nBins = 500\n",
    "hRange = (0, 100)\n",
    "\n",
    "counts, bin_edges, _ = plt.hist(data, bins=nBins, range=hRange, histtype=\"step\")\n",
    "\n",
    "bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "peaks, _ = find_peaks(counts, height=0.01, distance=6)\n",
    "\n",
    "plt.plot(bin_centers[peaks], counts[peaks], \"x\", color=\"black\", markersize=6)\n",
    "\n",
    "centroids = []\n",
    "centroid_errors = []\n",
    "sigmas = []\n",
    "sigma_errors = []\n",
    "\n",
    "for peak_index in peaks:\n",
    "    centroid, centroid_error, sigma, sigma_error, params = fit_gaussian_to_peak(\n",
    "        bin_centers, counts, peak_index\n",
    "    )\n",
    "    if centroid is not None:\n",
    "        centroids.append(centroid)\n",
    "        centroid_errors.append(centroid_error)\n",
    "        sigmas.append(sigma)\n",
    "        sigma_errors.append(sigma_error)\n",
    "\n",
    "        g_data = gaussian(bin_centers, *params)\n",
    "\n",
    "        plt.plot(bin_centers, g_data, alpha=0.3)\n",
    "        plt.errorbar(\n",
    "            centroid,\n",
    "            np.interp(centroid, bin_centers, counts),\n",
    "            xerr=error,\n",
    "            fmt=\"ro\",\n",
    "            label=\"Peaks with errors\",\n",
    "            capsize=10,\n",
    "            alpha=0.3,\n",
    "        )\n",
    "\n",
    "# Generate new \"fit\" laser positions by sampling around centroids\n",
    "new_centroids = np.random.normal(centroids, centroid_errors)\n",
    "new_sigmas = np.random.normal(sigmas, sigma_errors)\n",
    "\n",
    "# Recalibrate with degree 2 polynomial\n",
    "lowest_photon_number = new_centroids[1] // 3.5\n",
    "lowest_photon_number = (\n",
    "    lowest_photon_number\n",
    "    if np.abs(3.5 * lowest_photon_number - new_centroids[0])\n",
    "    < (np.abs(3.5 * (lowest_photon_number + 1) - new_centroids[0]))\n",
    "    else lowest_photon_number + 1\n",
    ")\n",
    "photon_energies = [(i + lowest_photon_number) * 3.5 for i in range(len(new_centroids))]\n",
    "calibration = np.poly1d(np.polyfit(new_centroids, photon_energies, 2))\n",
    "\n",
    "print(calibration)\n",
    "\n",
    "shift = calibration(bin_centers)  # apply calibration\n",
    "plt.plot(shift, counts, color=\"orange\", linewidth=2)  # replot\n",
    "\n",
    "\n",
    "for i in range(1, 20):\n",
    "    plt.axvline(i * 3.5, color=\"black\", alpha=0.2)\n",
    "\n",
    "\n",
    "plt.title(f\"Peak Amplitude Voltage Spectrum, Channel {channel}\")\n",
    "plt.xlabel(\"Voltage [mV]\")\n",
    "plt.ylabel(\"[Counts/0.2mV]\")\n",
    "plt.tight_layout()\n",
    "plt.xlim(hRange)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ce5a9-131c-4ff3-82f2-3368e2532315",
   "metadata": {},
   "source": [
    "# Multithread testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9698b-93c6-47ba-af34-b78dd93729eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(directory, subpaths[1] + \"/*.bin\"))\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bea38a-db6e-401e-a024-e129aaf8843b",
   "metadata": {},
   "source": [
    "# 6 hour processing time estimate (channel 10 is bad which is why the index errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f57d66-8c1f-477b-91ed-3eda070fb579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, header, ktpz = load_and_process(files[0], multithread=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7c4db-2d21-44e5-ba2f-4d4989670070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(\"trace\", axis=1, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ff0d9-025e-4366-86b6-a7120e85e9ce",
   "metadata": {},
   "source": [
    "# pre-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f1a46-7107-4017-af24-183263c7b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in df1[\"channel\"].unique():\n",
    "\n",
    "    micro_df = df1[df1[\"channel\"] == channel]\n",
    "\n",
    "    max_sumV = max(micro_df[\"sumV\"])\n",
    "    filt = micro_df[\n",
    "        (micro_df[\"otherV\"] < 2000) & (micro_df[\"multiplicity\"] >= 3)\n",
    "    ]  # we dont want multiplicty 2\n",
    "    filt2 = micro_df[(micro_df[\"otherV\"] < 2000) & (micro_df[\"multiplicity\"] == 1)]\n",
    "    data = filt[\"height_mV\"]\n",
    "    data2 = filt2[\"height_mV\"]\n",
    "\n",
    "    plt.figure(figsize=(9, 5))\n",
    "\n",
    "    nBins = 500\n",
    "    hRange = (0, 100)\n",
    "\n",
    "    counts, edges = np.histogram(data, bins=nBins, range=hRange)\n",
    "    max_bin_index = np.argmax(counts)\n",
    "    max_bin_value = edges[max_bin_index]\n",
    "\n",
    "    counts, bin_edges, _ = plt.hist(data, bins=nBins, range=hRange, histtype=\"step\")\n",
    "    plt.hist(data2, bins=nBins, range=hRange, histtype=\"step\", color=\"red\")\n",
    "\n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "    plt.title(f\"Peak Amplitude Voltage Spectrum, Channel {channel}\")\n",
    "    plt.xlabel(\"Millivolts\")\n",
    "    plt.ylabel(\"[Counts/0.2mV]\")\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(hRange)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b012f4-e66e-4a75-84f4-400a573b02a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel = 5  # for previews\n",
    "\n",
    "x = x / 5  # dont run this\n",
    "\n",
    "# save_file = \"20241012_Photoresist_7_23_processed_cleaning_tagged.csv\"\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    print(\"/n----------------------------\")\n",
    "    print(f\"Processing file {i} of {len(files)}\")\n",
    "    if i == 0:\n",
    "        print(\"skipping seed file\")\n",
    "    else:\n",
    "        try:\n",
    "            df, _, _ = load_and_process(file, known_tpz=ktpz, multithread=True)\n",
    "            df.drop(\"trace\", axis=1, inplace=True)\n",
    "            df1 = pd.concat([df1, df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    print(df1)\n",
    "    # save progress\n",
    "    # df1.to_csv(save_file, mode='w', index=False)\n",
    "    # plot\n",
    "\n",
    "    # plots for my sanity\n",
    "\n",
    "    micro_df = df1[df1[\"channel\"] == channel]\n",
    "\n",
    "    max_sumV = max(micro_df[\"sumV\"])\n",
    "    filt = micro_df[(micro_df[\"otherV\"] < 2000) & (micro_df[\"multiplicity\"] >= 2)]\n",
    "    data = filt[\"height_mV\"]\n",
    "    plt.figure(figsize=(9, 5))\n",
    "\n",
    "    nBins = 500\n",
    "    hRange = (0, 100)\n",
    "\n",
    "    counts, edges = np.histogram(data, bins=nBins, range=hRange)\n",
    "    max_bin_index = np.argmax(counts)\n",
    "    max_bin_value = edges[max_bin_index]\n",
    "\n",
    "    counts, bin_edges, _ = plt.hist(data, bins=nBins, range=hRange, histtype=\"step\")\n",
    "\n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "    plt.title(f\"Voltage Spectrum, Channel {channel}, ~{20000*(i+1)} counts\")\n",
    "    plt.xlabel(\"Voltage [mV]\")\n",
    "    plt.ylabel(\"Counts [0.2/mV]\")\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(hRange)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d012653b-ebba-4df1-8038-277e95349234",
   "metadata": {},
   "source": [
    "# post output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0607e-c539-4d35-965f-fde5379f4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b64c031-0afd-42fb-ae93-609ae7a9c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in df1[\"channel\"].unique():\n",
    "\n",
    "    micro_df = df1[df1[\"channel\"] == channel]\n",
    "\n",
    "    max_sumV = max(micro_df[\"sumV\"])\n",
    "    filt = micro_df[\n",
    "        (micro_df[\"otherV\"] < 2000) & (micro_df[\"multiplicity\"] >= 3)\n",
    "    ]  # we dont want multiplicty 2\n",
    "    filt2 = micro_df[(micro_df[\"otherV\"] < 2000) & (micro_df[\"multiplicity\"] == 1)]\n",
    "    data = filt[\"height_mV\"]\n",
    "    data2 = filt2[\"height_mV\"]\n",
    "\n",
    "    plt.figure(figsize=(9, 5))\n",
    "\n",
    "    nBins = 500\n",
    "    hRange = (0, 100)\n",
    "\n",
    "    counts, edges = np.histogram(data, bins=nBins, range=hRange)\n",
    "    max_bin_index = np.argmax(counts)\n",
    "    max_bin_value = edges[max_bin_index]\n",
    "\n",
    "    counts, bin_edges, _ = plt.hist(data, bins=nBins, range=hRange, histtype=\"step\")\n",
    "    plt.hist(data2, bins=nBins, range=hRange, histtype=\"step\", color=\"red\")\n",
    "\n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "    plt.title(f\"Peak Amplitude Voltage Spectrum, Channel {channel}\")\n",
    "    plt.xlabel(\"Millivolts\")\n",
    "    plt.ylabel(\"[Counts/0.2mV]\")\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(hRange)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51e139-aa9b-4554-8be0-ca81c5b85b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"20241012_Photoresist_7_23_processed_cleaning_tagged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c72656-0c9c-41d8-9fce-e508d819258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572b7cc-79fe-4488-9b50-658645a5259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0\n",
    "\n",
    "micro_df = df2[df2[\"channel\"] == channel]\n",
    "max_sumV = max(micro_df[\"sumV\"])\n",
    "filt = micro_df[(micro_df[\"otherV\"] < 10000) & (micro_df[\"multiplicity\"] >= 2)]\n",
    "filt_be7 = micro_df[(micro_df[\"otherV\"] < 10000) & (micro_df[\"multiplicity\"] == 1)]\n",
    "\n",
    "data = filt[\"height_mV\"]\n",
    "data_be7 = filt_be7[\"height_mV\"]\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "\n",
    "nBins = 500\n",
    "hRange = (0, 100)\n",
    "\n",
    "counts, bin_edges, _ = plt.hist(\n",
    "    data,\n",
    "    bins=nBins,\n",
    "    range=hRange,\n",
    "    histtype=\"step\",\n",
    "    label=f\"Laser [Counts/0.2mV], M >= 2: {len(data)}\",\n",
    ")\n",
    "counts_be7, _ = np.histogram(data_be7, bins=nBins, range=hRange)\n",
    "\n",
    "bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "peaks, _ = find_peaks(counts, height=0.01, distance=6)\n",
    "\n",
    "plt.plot(bin_centers[peaks], counts[peaks], \"x\", color=\"black\", markersize=6)\n",
    "\n",
    "centroids = []\n",
    "centroid_errors = []\n",
    "sigmas = []\n",
    "sigma_errors = []\n",
    "\n",
    "for peak_index in peaks:\n",
    "    centroid, centroid_error, sigma, sigma_error, params = fit_gaussian_to_peak(\n",
    "        bin_centers, counts, peak_index\n",
    "    )\n",
    "    if centroid is not None:\n",
    "        centroids.append(centroid)\n",
    "        centroid_errors.append(centroid_error)\n",
    "        sigmas.append(sigma)\n",
    "        sigma_errors.append(sigma_error)\n",
    "\n",
    "        g_data = gaussian(bin_centers, *params)\n",
    "\n",
    "        plt.plot(bin_centers, g_data, alpha=0.4, linewidth=0.5, linestyle=\"--\")\n",
    "        # plt.errorbar(centroid, np.interp(centroid, bin_centers, counts), xerr=error, fmt='ro', label=\"Peaks with errors\", capsize=10, alpha=0.3)\n",
    "\n",
    "# Generate new \"fit\" laser positions by sampling around centroids\n",
    "\n",
    "# cuttoff low and highh\n",
    "low = 1\n",
    "high = 32\n",
    "\n",
    "centroids = centroids[low:high]\n",
    "centroid_errors = centroid_errors[low:high]\n",
    "sigmas = sigmas[low:high]\n",
    "sigma_errors = sigma_errors[low:high]\n",
    "\n",
    "new_centroids = np.random.normal(centroids, centroid_errors)\n",
    "new_sigmas = np.random.normal(sigmas, sigma_errors)\n",
    "\n",
    "# Recalibrate with degree 2 polynomial\n",
    "lowest_photon_number = new_centroids[1] // 3.5\n",
    "lowest_photon_number = (\n",
    "    lowest_photon_number\n",
    "    if np.abs(3.5 * lowest_photon_number - new_centroids[0])\n",
    "    < (np.abs(3.5 * (lowest_photon_number + 1) - new_centroids[0]))\n",
    "    else lowest_photon_number + 1\n",
    ")\n",
    "photon_energies = [(i + lowest_photon_number) * 3.5 for i in range(len(new_centroids))]\n",
    "calibration = np.poly1d(np.polyfit(new_centroids, photon_energies, 2))\n",
    "\n",
    "print(calibration)\n",
    "\n",
    "shift = calibration(bin_centers)  # apply calibration\n",
    "plt.step(\n",
    "    shift,\n",
    "    counts,\n",
    "    color=\"orange\",\n",
    "    linewidth=1,\n",
    "    label=f\"Laser [Counts/0.2eV], M >= 2: {len(data)}\",\n",
    ")  # replot\n",
    "plt.step(\n",
    "    shift[30:],\n",
    "    counts_be7[30:] * 300,\n",
    "    color=\"red\",\n",
    "    linewidth=1,\n",
    "    label=f\"Be7 [300*Counts/0.2eV], M == 1: {len(data_be7)}\",\n",
    ")\n",
    "\n",
    "for i in range(1, 50):\n",
    "    plt.axvline(i * 3.5, color=\"grey\", alpha=0.2)\n",
    "\n",
    "plt.axvline(107.92, color=\"green\", linestyle=\"--\", label=\"107.92 eV\")\n",
    "\n",
    "\n",
    "plt.title(f\"Voltage/Energy Spectrum, Channel {channel}\")\n",
    "plt.xlabel(\"Blue-Voltage[mV], Orange-Energy[eV]\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.xlim(0, 175)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d03b32-3c1f-4cb4-b5c0-6e7be6184de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.step(\n",
    "    shift,\n",
    "    counts,\n",
    "    color=\"orange\",\n",
    "    linewidth=1,\n",
    "    label=f\"Laser [Counts/0.2eV], M >= 2: {len(data)}\",\n",
    ")  # replot\n",
    "plt.step(\n",
    "    shift[15:],\n",
    "    counts_be7[15:] * 300,\n",
    "    color=\"red\",\n",
    "    linewidth=1,\n",
    "    label=f\"Be7 [300*Counts/0.2eV], M == 1: {len(data_be7)}\",\n",
    ")\n",
    "plt.axvline(107.92, color=\"green\", linestyle=\"--\", label=\"107.92 eV\")\n",
    "\n",
    "plt.title(\"Channel 0 Spectra\")\n",
    "plt.xlabel(\"Energy [eV]\")\n",
    "plt.ylabel(\"[Counts/0.2eV]\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(0, 175)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc7f90-df56-4041-8249-3106dfea8288",
   "metadata": {},
   "source": [
    "# Be7 Spectrum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13af665-cd23-4153-a850-253f38be383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"20241010_processed_uncleaned.csv\")\n",
    "df2 = pd.read_csv(\"20241012_Photoresist_7_23_processed_cleaning_tagged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4b200-387f-4b93-a7d0-4e932e67968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce36a60-5bfa-4b0d-9ccf-e7cb9c721ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration_function(bin_centers, counts_laser, low_cut, high_cut):\n",
    "    peaks, _ = find_peaks(counts_laser, height=0.01, distance=6)\n",
    "\n",
    "    # fit gaussians and get errors\n",
    "    centroids = []\n",
    "    centroid_errors = []\n",
    "    sigmas = []\n",
    "    sigma_errors = []\n",
    "\n",
    "    for peak_index in peaks:\n",
    "        centroid, centroid_error, sigma, sigma_error, params = fit_gaussian_to_peak(\n",
    "            bin_centers, counts_laser, peak_index\n",
    "        )\n",
    "        if centroid is not None:\n",
    "            centroids.append(centroid)\n",
    "            centroid_errors.append(centroid_error)\n",
    "            sigmas.append(sigma)\n",
    "            sigma_errors.append(sigma_error)\n",
    "\n",
    "    centroids = centroids[low_cut:high_cut]\n",
    "    centroid_errors = centroid_errors[low_cut:high_cut]\n",
    "    sigmas = sigmas[low_cut:high_cut]\n",
    "    sigma_errors = sigma_errors[low_cut:high_cut]\n",
    "\n",
    "    new_centroids = np.random.normal(centroids, centroid_errors)\n",
    "    new_sigmas = np.random.normal(sigmas, sigma_errors)\n",
    "\n",
    "    # Recalibrate with degree 2 polynomial\n",
    "    lowest_photon_number = new_centroids[1] // 3.5\n",
    "    lowest_photon_number = (\n",
    "        lowest_photon_number\n",
    "        if np.abs(3.5 * lowest_photon_number - new_centroids[0])\n",
    "        < (np.abs(3.5 * (lowest_photon_number + 1) - new_centroids[0]))\n",
    "        else lowest_photon_number + 1\n",
    "    )\n",
    "    photon_energies = [\n",
    "        (i + lowest_photon_number) * 3.5 for i in range(len(new_centroids))\n",
    "    ]\n",
    "    calibration = np.poly1d(np.polyfit(new_centroids, photon_energies, 2))\n",
    "\n",
    "    return calibration\n",
    "\n",
    "\n",
    "def cutoff_helper_plot(df, channel, low_cut=5, high_cut=15):\n",
    "    # generates mV spectrum to visually help choose the peak cutoffs for calibration\n",
    "    micro_df = df[df[\"channel\"] == channel]\n",
    "    filt_laser = micro_df[\n",
    "        (micro_df[\"otherV\"] < 10000) & (micro_df[\"multiplicity\"] >= 2)\n",
    "    ]\n",
    "    data_laser = filt_laser[\"height_mV\"]\n",
    "\n",
    "    nBins = 500\n",
    "    hRange = (0, 100)\n",
    "\n",
    "    counts_laser, bin_edges = np.histogram(data_laser, bins=nBins, range=hRange)\n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "    peaks, _ = find_peaks(counts_laser, height=0.01, distance=6)\n",
    "    calibration = get_calibration_function(bin_centers, counts_laser, low_cut, high_cut)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(9, 6))\n",
    "\n",
    "    ax[0].step(bin_centers, counts_laser, linewidth=0.5, color=\"blue\")\n",
    "    for i, peak in enumerate(peaks):\n",
    "        if i == low_cut or i == high_cut:\n",
    "            ax[0].axvline(bin_centers[peak], color=\"red\")\n",
    "        ax[0].step(bin_centers[peak], counts_laser[peak], \"ro\", markersize=1)\n",
    "        ax[0].text(bin_centers[peak] - 1, counts_laser[peak] + 100, f\"{i}\", fontsize=6)\n",
    "\n",
    "    ax[1].step(calibration(bin_centers), counts_laser, linewidth=0.5, color=\"orange\")\n",
    "    ax[1].step(\n",
    "        calibration(bin_centers) + 3.5 * (low_cut),\n",
    "        counts_laser,\n",
    "        linewidth=0.5,\n",
    "        color=\"green\",\n",
    "    )\n",
    "    for i in range(1, 50):\n",
    "        ax[1].axvline(i * 3.5, color=\"grey\", alpha=0.2)\n",
    "    ax[1].set_xlim(-20, 100)  # to show offset\n",
    "\n",
    "    ax[0].set_title(f\"Channel {channel}, cutoffs=({low_cut}, {high_cut})\")\n",
    "    ax[0].set_ylabel(\"[Counts/0.2mV]\")\n",
    "    ax[0].set_xlabel(\"Voltage [mV]\")\n",
    "\n",
    "    ax[1].set_ylabel(\"[Counts/0.2eV]\")\n",
    "    ax[1].set_xlabel(\"Energy [eV]\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def calibrate_voltage_to_energy(df, channel, low_cut, high_cut, debug_plot=False):\n",
    "\n",
    "    if debug_plot:\n",
    "        plt.figure(figsize=(9, 5))\n",
    "\n",
    "    micro_df = df[df[\"channel\"] == channel]\n",
    "    filt_laser = micro_df[\n",
    "        (micro_df[\"otherV\"] < 10000) & (micro_df[\"multiplicity\"] >= 2)\n",
    "    ]\n",
    "    filt_be7 = micro_df[(micro_df[\"otherV\"] < 10000) & (micro_df[\"multiplicity\"] == 1)]\n",
    "\n",
    "    data_laser = filt_laser[\"height_mV\"]\n",
    "    data_be7 = filt_be7[\"height_mV\"]\n",
    "\n",
    "    nBins = 500\n",
    "    hRange = (0, 100)\n",
    "\n",
    "    counts_laser, bin_edges = np.histogram(data_laser, bins=nBins, range=hRange)\n",
    "    counts_be7, _ = np.histogram(data_be7, bins=nBins, range=hRange)\n",
    "\n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "    calibration = get_calibration_function(bin_centers, counts_laser, low_cut, high_cut)\n",
    "\n",
    "    if debug_plot:\n",
    "        print(calibration)\n",
    "        shift = calibration(bin_centers)\n",
    "        plt.step(\n",
    "            shift, counts_laser, color=\"orange\", linewidth=1, label=f\"Laser, M >= 2\"\n",
    "        )\n",
    "        plt.step(\n",
    "            shift[30:],\n",
    "            counts_be7[30:] * 300,\n",
    "            color=\"red\",\n",
    "            linewidth=1,\n",
    "            label=f\"Be7, M == 1\",\n",
    "        )\n",
    "\n",
    "        # Draw calibration lines\n",
    "        for i in range(1, 50):\n",
    "            plt.axvline(i * 3.5, color=\"grey\", alpha=0.2)\n",
    "\n",
    "        plt.axvline(107.92, color=\"green\", linestyle=\"--\", label=\"107.92 eV\")\n",
    "        plt.title(f\"Voltage/Energy Spectrum, Channel {channel}\")\n",
    "        plt.xlabel(\"Energy[eV]\")\n",
    "        plt.ylabel(\"[Counts/0.2eV]\")\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.xlim(0, 175)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    return calibration, bin_centers, counts_laser, counts_be7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b8d066-2792-4016-af5a-af8880e39ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_channels = [0, 2, 3, 4, 5, 8, 9, 10, 13, 14, 17, 18, 19, 20, 21, 26, 28]  # 7/22\n",
    "d1_cutoffs = [\n",
    "    (0, 15),\n",
    "    (2, 9),\n",
    "    (2, 10),\n",
    "    (3, 12),\n",
    "    (4, 15),\n",
    "    (4, 15),\n",
    "    (5, 12),\n",
    "    (5, 14),\n",
    "    (4, 9),\n",
    "    (5, 23),\n",
    "    (4, 12),\n",
    "    (4, 12),\n",
    "    (5, 15),\n",
    "    (5, 15),\n",
    "    (3, 10),\n",
    "    (2, 9),\n",
    "    (5, 19),\n",
    "]\n",
    "\n",
    "day2_channels = [0, 3, 5, 8, 9, 11, 17, 19, 20, 21]  # 7/23\n",
    "\n",
    "channel = 2\n",
    "cuts = d1_cutoffs[channel]\n",
    "cutoff_helper_plot(df1, channel, low_cut=cuts[0], high_cut=cuts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab69617-7ee2-4441-b5a7-864c1e017e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration1, bins1, laser1, be1 = calibrate_voltage_to_energy(df1, 0, 4, 15)\n",
    "calibration2, bins2, laser2, be2 = calibrate_voltage_to_energy(\n",
    "    df1, 2, 2, 9, debug_plot=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.step(calibration1(bins1) + 1 * 3.5, laser1)\n",
    "plt.step(calibration2(bins2) + 2 * 3.5, laser2)\n",
    "\n",
    "for i in range(1, 50):\n",
    "    plt.axvline(i * 3.5, color=\"grey\", alpha=0.2)\n",
    "\n",
    "plt.xlim(-10, 100)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad135f-7f94-46c4-b795-2d55fdfc15bc",
   "metadata": {},
   "source": [
    "## Pretty Plot For Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df8d46-d5de-47ed-b27d-fe449ffbb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0\n",
    "\n",
    "micro_df = df2[df2[\"channel\"] == channel]\n",
    "max_sumV = max(micro_df[\"sumV\"])\n",
    "filt = micro_df[(micro_df[\"otherV\"] < 10000) & (micro_df[\"multiplicity\"] >= 2)]\n",
    "filt_be7 = micro_df[(micro_df[\"otherV\"] < 10000) & (micro_df[\"multiplicity\"] == 1)]\n",
    "\n",
    "data = filt[\"height_mV\"]\n",
    "data_be7 = filt_be7[\"height_mV\"]\n",
    "\n",
    "plt.figure(figsize=(9, 5), dpi=400)\n",
    "\n",
    "nBins = 500\n",
    "hRange = (0, 100)\n",
    "\n",
    "counts, bin_edges = np.histogram(data, bins=nBins, range=hRange)\n",
    "counts_be7, _ = np.histogram(data_be7, bins=nBins, range=hRange)\n",
    "\n",
    "\n",
    "bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "peaks, _ = find_peaks(counts, height=0.01, distance=6)\n",
    "\n",
    "# plt.plot(bin_centers[peaks], counts[peaks], 'x', color='black', markersize=6)\n",
    "\n",
    "centroids = []\n",
    "centroid_errors = []\n",
    "sigmas = []\n",
    "sigma_errors = []\n",
    "\n",
    "for peak_index in peaks:\n",
    "    centroid, centroid_error, sigma, sigma_error, params = fit_gaussian_to_peak(\n",
    "        bin_centers, counts, peak_index\n",
    "    )\n",
    "    if centroid is not None:\n",
    "        centroids.append(centroid)\n",
    "        centroid_errors.append(centroid_error)\n",
    "        sigmas.append(sigma)\n",
    "        sigma_errors.append(sigma_error)\n",
    "\n",
    "        # g_data = gaussian(bin_centers, *params)\n",
    "\n",
    "        # plt.plot(bin_centers, g_data, alpha=0.4, linewidth=0.5, linestyle='--')\n",
    "        # plt.errorbar(centroid, np.interp(centroid, bin_centers, counts), xerr=error, fmt='ro', label=\"Peaks with errors\", capsize=10, alpha=0.3)\n",
    "\n",
    "# Generate new \"fit\" laser positions by sampling around centroids\n",
    "\n",
    "# cuttoff low and highh\n",
    "low = 1\n",
    "high = 32\n",
    "\n",
    "centroids = centroids[low:high]\n",
    "centroid_errors = centroid_errors[low:high]\n",
    "sigmas = sigmas[low:high]\n",
    "sigma_errors = sigma_errors[low:high]\n",
    "\n",
    "new_centroids = np.random.normal(centroids, centroid_errors)\n",
    "new_sigmas = np.random.normal(sigmas, sigma_errors)\n",
    "\n",
    "# Recalibrate with degree 2 polynomial\n",
    "lowest_photon_number = new_centroids[1] // 3.5\n",
    "lowest_photon_number = (\n",
    "    lowest_photon_number\n",
    "    if np.abs(3.5 * lowest_photon_number - new_centroids[0])\n",
    "    < (np.abs(3.5 * (lowest_photon_number + 1) - new_centroids[0]))\n",
    "    else lowest_photon_number + 1\n",
    ")\n",
    "photon_energies = [(i + lowest_photon_number) * 3.5 for i in range(len(new_centroids))]\n",
    "calibration = np.poly1d(np.polyfit(new_centroids, photon_energies, 2))\n",
    "\n",
    "print(calibration)\n",
    "\n",
    "shift = calibration(bin_centers)  # apply calibration\n",
    "plt.step(\n",
    "    bin_centers,\n",
    "    counts,\n",
    "    color=\"blue\",\n",
    "    linewidth=1,\n",
    "    label=f\"Laser [Counts/0.2mV], total counts: {len(data)}\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.step(\n",
    "    shift + 3.5,\n",
    "    counts,\n",
    "    color=\"black\",\n",
    "    linewidth=1,\n",
    "    label=f\"Laser [Counts/0.2eV], total counts: {len(data)}\",\n",
    ")  # replot\n",
    "plt.step(\n",
    "    shift + 3.5,\n",
    "    counts_be7 * 200,\n",
    "    color=\"red\",\n",
    "    linewidth=1,\n",
    "    label=f\"Be7 [200x Counts/0.2eV], total counts: {len(data_be7)}\",\n",
    ")\n",
    "\n",
    "for i in range(1, 52):\n",
    "    plt.axvline(i * 3.5, color=\"grey\", alpha=0.2)\n",
    "\n",
    "plt.axvline(\n",
    "    107.92,\n",
    "    color=\"green\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=1,\n",
    "    label=\"Expected K-GS Peak (107.92 eV)\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Energy [eV] (Black, Red), Voltage [mV] (Blue)\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.xlim(0, 180)\n",
    "plt.ylim(0, 10500)\n",
    "\n",
    "# plt.savefig(\"CalibratePhotoresistLaserSpectra.png\", dpi=400)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb352608-208f-46b2-9374-66444ee2717c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
